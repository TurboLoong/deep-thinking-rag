{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "toc-pro-adv",
   "metadata": {},
   "source": [
    "# A Guide to Production-Grade RAG: From Theory to Autonomous Agents\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "**Part 1: Setting the Stage - Foundations and Our Core Challenge**\n",
    "* [1.1. Introduction: The Limits of \"Shallow\" RAG](#part1-1-intro-pro)\n",
    "* [1.2. Environment Setup: API Keys, Imports, and Configuration](#part1-2-env-pro-adv)\n",
    "* [1.3. The Dataset: Preparing Our Knowledge Base](#part1-3-data-pro)\n",
    "* [1.4. The Upgraded Challenge: A Multi-Source, Multi-Hop Query](#part1-4-challenge-pro-adv)\n",
    "\n",
    "**Part 2: The Baseline - Building and Breaking a \"Vanilla\" RAG Pipeline**\n",
    "* [2.1. Code Dependency: Document Loading and Naive Chunking](#part2-1-dep-pro)\n",
    "* [2.2. Code Dependency: Creating the Vector Store](#part2-2-dep-pro)\n",
    "* [2.3. Code Dependency: Assembling the Simple RAG Chain](#part2-3-dep-pro)\n",
    "* [2.4. The Critical Failure Case: Demonstrating the Need for Advanced Techniques](#part2-4-fail-pro-adv)\n",
    "* [2.5. Diagnosis: Why Did It Fail?](#part2-5-diag-pro-adv)\n",
    "\n",
    "**Part 3: The \"Deep Thinking\" Upgrade: Engineering an Autonomous Reasoning Engine**\n",
    "* [3.1. Code Dependency: Defining the `RAGState`](#part3-1-state-pro-adv)\n",
    "* [3.2. Component 1: Dynamic Planning and Query Formulation](#part3-2-planner-pro-adv)\n",
    "    * [3.2.1. The Tool-Aware Planner Agent](#part3-2-1-planner-pro-adv)\n",
    "    * [3.2.2. Query Rewriting and Expansion](#part3-2-2-rewriter-pro)\n",
    "    * [3.2.3. Entity and Constraint Extraction](#part3-2-3-metadata-pro)\n",
    "* [3.3. Component 2: The Multi-Stage, Adaptive Retrieval Funnel](#part3-3-retrieval-pro-adv)\n",
    "    * [3.3.1. NEW: The Retrieval Supervisor Agent](#part3-3-1-supervisor-pro)\n",
    "    * [3.3.2. Implementing the Retrieval Strategies](#part3-3-2-strategies-pro)\n",
    "    * [3.3.3. Stage 2 (High Precision): Cross-Encoder Reranker](#part3-3-3-reranker-pro)\n",
    "    * [3.3.4. Stage 3 (Contextual Distillation)](#part3-3-4-distill-pro)\n",
    "* [3.4. Component 3: Tool Augmentation with Web Search](#part3-4-tool-pro)\n",
    "* [3.5. Component 4: The Self-Critique and Control Flow Policy](#part3-5-critique-pro)\n",
    "    * [3.5.1. The \"Update and Reflect\" Step](#part3-5-1-reflect-pro)\n",
    "    * [3.5.2. Policy Implementation (LLM-as-a-Judge)](#part3-5-2-policy-pro)\n",
    "    * [3.5.3. Defining Robust Stopping Criteria](#part3-5-3-stopping-pro)\n",
    "\n",
    "**Part 4: Assembly with LangGraph - Orchestrating the Reasoning Loop**\n",
    "* [4.1. Code Dependency: Defining the Graph Nodes](#part4-1-nodes-pro-adv)\n",
    "* [4.2. Code Dependency: Defining the Conditional Edges](#part4-2-edges-pro-adv)\n",
    "* [4.3. Building the `StateGraph`](#part4-3-build-pro-adv)\n",
    "* [4.4. Compiling and Visualizing the Workflow](#part4-4-viz-pro-adv)\n",
    "\n",
    "**Part 5: Redemption - Running the Advanced Agent**\n",
    "* [5.1. Invoking the Graph: A Step-by-Step Trace](#part5-1-invoke-pro-adv)\n",
    "* [5.2. Analyzing the Final High-Quality Output](#part5-2-analyze-pro-adv)\n",
    "* [5.3. Side-by-Side Comparison: Vanilla vs. Deep Thinking RAG](#part5-3-compare-pro-adv)\n",
    "\n",
    "**Part 6: A Production-Grade Evaluation Framework**\n",
    "* [6.1. Evaluation Metrics Overview](#part6-metrics-pro)\n",
    "* [6.2. Code Dependency: Implementing Evaluation with RAGAs](#part6-4-ragas-code-pro-adv)\n",
    "* [6.3. Interpreting the Evaluation Scores](#part6-5-interpret-pro-adv)\n",
    "\n",
    "**Part 7: Optimizations and Production Considerations**\n",
    "* [7.1. Optimization: Caching](#part7-1-cache-pro)\n",
    "* [7.2. Feature: Provenance and Citations](#part7-2-provenance-pro)\n",
    "* [7.3. Discussion: The Next Level - MDPs and Learned Policies](#part7-3-discussion-pro)\n",
    "* [7.4. Handling Failure: Graceful Exits and Fallbacks](#part7-4-failure-pro)\n",
    "\n",
    "**Part 8: Conclusion and Key Takeaways**\n",
    "* [8.1. Summary of Our Journey](#part8-conclusion-pro)\n",
    "* [8.2. Key Architectural Principles of Advanced RAG Systems](#part8-2-principles-pro-adv)\n",
    "* [8.3. Future Directions](#part8-3-future-pro-adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-intro-rag-pro",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Stage - Foundations and Our Core Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-1-intro-pro",
   "metadata": {},
   "source": [
    "### 1.1. Introduction: The Limits of \"Shallow\" RAG\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) has become the dominant paradigm for creating knowledge-intensive AI systems. The standard approach—a linear, three-step pipeline of **Retrieve -> Augment -> Generate**—is remarkably effective for simple, fact-based queries. However, this \"shallow\" RAG architecture reveals critical weaknesses when faced with complex questions that demand synthesis, comparison, and multi-step reasoning across a large and varied knowledge base.\n",
    "\n",
    "The next frontier in RAG is not about bigger models or larger context windows, but about greater **autonomy and intelligence** in the retrieval and reasoning process. The industry is moving from static chains to dynamic, agentic systems that can emulate a human researcher's workflow. These systems can decompose complex problems, select appropriate tools, dynamically adapt their retrieval strategies, and critique their own progress.\n",
    "\n",
    "In this comprehensive guide, we will build a powerful, **standalone** implementation of a **Deep Thinking RAG Pipeline**. We will meticulously engineer every component, from a sophisticated multi-stage, adaptive retrieval funnel to a tool-augmented, self-critiquing policy engine. We will begin by exposing the failure of a vanilla RAG system on a challenging query, and then, step-by-step, construct our advanced agent using **LangGraph** to orchestrate its complex, cyclical reasoning. By the end, you will have a production-grade framework and a deep, architectural understanding of how to build RAG systems that can truly *think*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-2-env-pro-adv",
   "metadata": {},
   "source": [
    "### 1.2. Environment Setup: API Keys, Imports, and Configuration\n",
    "\n",
    "We begin by setting up our foundational components. This includes securely managing API keys, importing all necessary libraries, and defining a global configuration dictionary. We will use **LangSmith** for tracing, which is an indispensable tool for visualizing and debugging the complex, non-linear execution paths of our reasoning agent. For our new web search capability, we will also add the **Tavily AI** API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "part1-2-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and configuration set up successfully.\n",
      "{'data_dir': './data',\n",
      " 'embedding_model': 'BAAI/bge-m3',\n",
      " 'fast_llm': 'Qwen/Qwen3-14B',\n",
      " 'llm_provider': 'openai',\n",
      " 'max_reasoning_iterations': 7,\n",
      " 'reasoning_llm': 'Qwen/Qwen3-32B',\n",
      " 'reranker_model': 'BAAI/bge-reranker-v2-m3',\n",
      " 'top_k_retrieval': 10,\n",
      " 'top_n_rerank': 3,\n",
      " 'vector_store_dir': './vector_store'}\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U langchain langgraph langchain_openai chromadb beautifulsoup4 rank_bm25 lxml sentence-transformers cross-encoder ragas arxiv rich sec-api unstructured[html] tavily-python\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from getpass import getpass\n",
    "from pprint import pprint\n",
    "import uuid\n",
    "from typing import List, Dict, TypedDict, Literal, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Securely set API keys\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass(f\"Enter your {var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "# _set_env(\"LANGSMITH_API_KEY\")\n",
    "# _set_env(\"TAVILY_API_KEY\")\n",
    "# Optional: For accessing SEC filings programmatically\n",
    "# _set_env(\"SEC_API_KEY\")\n",
    "\n",
    "# Configure LangSmith tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Advanced-Deep-Thinking-RAG-v2\"\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7897'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7897'\n",
    "# Central Configuration Dictionary\n",
    "config = {\n",
    "    \"data_dir\": \"./data\",\n",
    "    \"vector_store_dir\": \"./vector_store\",\n",
    "    \"llm_provider\": \"openai\",\n",
    "    \"reasoning_llm\": \"Qwen/Qwen3-32B\",\n",
    "    \"fast_llm\": \"Qwen/Qwen3-14B\",\n",
    "    \"embedding_model\": \"BAAI/bge-m3\",\n",
    "    \"reranker_model\": \"BAAI/bge-reranker-v2-m3\",\n",
    "    \"max_reasoning_iterations\": 7, # Maximum loops for the reasoning agent\n",
    "    \"top_k_retrieval\": 10,       # Number of documents for initial broad recall\n",
    "    \"top_n_rerank\": 3,           # Number of documents to keep after precision reranking\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(config[\"data_dir\"], exist_ok=True)\n",
    "os.makedirs(config[\"vector_store_dir\"], exist_ok=True)\n",
    "\n",
    "print(\"Environment and configuration set up successfully.\")\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-3-data-pro",
   "metadata": {},
   "source": [
    "### 1.3. The Dataset: Preparing Our Knowledge Base from Complex Documents\n",
    "\n",
    "Our knowledge base will be the full text of NVIDIA's 2023 10-K filing. Instead of a dummy file, we will programmatically download the actual filing from the SEC's EDGAR database. This document is a dense, 100+ page report detailing their business, financials, and risks. This is a perfect test case because answering sophisticated questions requires connecting information spread across disparate sections like 'Business Overview', 'Risk Factors', and 'Management's Discussion and Analysis' (MD&A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "part1-3-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and parsing NVIDIA's 2023 10-K filing...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "def download_and_parse_10k(url, doc_path_raw, doc_path_clean):\n",
    "    if os.path.exists(doc_path_clean):\n",
    "        print(f\"Cleaned 10-K file already exists at: {doc_path_clean}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading 10-K filing from {url}...\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',\n",
    "    \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "    \"accept-language\": \"zh,en;q=0.9,en-US;q=0.8,zh-CN;q=0.7\",\n",
    "    \"cache-control\": \"no-cache\",\n",
    "    \"pragma\": \"no-cache\",\n",
    "    \"priority\": \"u=0, i\",\n",
    "    \"sec-ch-ua\": 'Google Chrome;v=\"143\", \"Chromium\";v=\"143\", \"Not A(Brand\";v=\"24\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"Windows\",\n",
    "    \"sec-fetch-dest\": \"document\",\n",
    "    \"sec-fetch-mode\": \"navigate\",\n",
    "    \"sec-fetch-site\": \"none\",\n",
    "    \"sec-fetch-user\": \"?1\",\n",
    "    \"upgrade-insecure-requests\": \"1\"\n",
    "               }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status() # Ensure we got a valid response\n",
    "    \n",
    "    with open(doc_path_raw, 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "    print(f\"Raw document saved to {doc_path_raw}\")\n",
    "    \n",
    "    # Use BeautifulSoup to parse and clean the HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Remove tables, which are often noisy for text-based RAG\n",
    "    for table in soup.find_all('table'):\n",
    "        table.decompose()\n",
    "\n",
    "    # Get clean text, attempting to preserve paragraph breaks\n",
    "    text = ''\n",
    "    for p in soup.find_all(['p', 'div', 'span']):\n",
    "        # Simple heuristic to add newlines between blocks\n",
    "        text += p.get_text(strip=True) + '\\n\\n'\n",
    "    \n",
    "    # A more robust regex to clean up excessive newlines and whitespace\n",
    "    clean_text = re.sub(r'\\n{3,}', '\\n\\n', text).strip()\n",
    "    clean_text = re.sub(r'\\s{2,}', ' ', clean_text).strip()\n",
    "    \n",
    "    with open(doc_path_clean, 'w', encoding='utf-8') as f:\n",
    "        f.write(clean_text)\n",
    "    print(f\"Cleaned text content extracted and saved to {doc_path_clean}\")\n",
    "\n",
    "# URL for NVIDIA's 2023 10-K filing (filed Feb 2023 for fiscal year ending Jan 2023)\n",
    "url_10k = \"https://www.sec.gov/Archives/edgar/data/1045810/000104581023000017/nvda-20230129.htm\"\n",
    "doc_path_raw = os.path.join(config[\"data_dir\"], \"nvda_10k_2023_raw.html\")\n",
    "doc_path_clean = os.path.join(config[\"data_dir\"], \"nvda_10k_2023_clean.txt\")\n",
    "\n",
    "print(\"Downloading and parsing NVIDIA's 2023 10-K filing...\")\n",
    "# download_and_parse_10k(url_10k, doc_path_raw, doc_path_clean)\n",
    "\n",
    "# with open(doc_path_clean, 'r', encoding='utf-8') as f:\n",
    "#     print(\"--- Sample content from cleaned 10-K ---\")\n",
    "#     print(f.read(1000) + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-4-challenge-pro-adv",
   "metadata": {},
   "source": [
    "### 1.4. The Upgraded Challenge: A Multi-Source, Multi-Hop Query We Will Conquer\n",
    "\n",
    "This is the query designed to break our baseline RAG system and showcase the power of our advanced agent. It requires the agent to perform multiple distinct information retrieval steps from *different sources* (the static 10-K and the live web) and then synthesize the findings into a coherent analytical narrative.\n",
    "\n",
    "> **The Query:** \"Based on NVIDIA's 2023 10-K filing, identify their key risks related to competition. Then, find recent news (post-filing, from 2024) about AMD's AI chip strategy and explain how this new strategy directly addresses or exacerbates one of NVIDIA's stated risks.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-intro-rag-pro",
   "metadata": {},
   "source": [
    "## Part 2: The Baseline - Building and Breaking a \"Vanilla\" RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-1-dep-pro",
   "metadata": {},
   "source": [
    "### 2.1. Code Dependency: Document Loading and Naive Chunking Strategy\n",
    "\n",
    "Our baseline pipeline begins with a standard approach: load the entire document and split it into fixed-size chunks using a `RecursiveCharacterTextSplitter`. This method is fast but semantically naive, often splitting paragraphs or related ideas across different chunks—a primary source of failure for complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "part2-1-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and chunking the document...\n",
      "Document loaded and split into 693 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(\"Loading and chunking the document...\")\n",
    "loader = TextLoader(doc_path_clean, encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "doc_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Document loaded and split into {len(doc_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-2-dep-pro",
   "metadata": {},
   "source": [
    "### 2.2. Code Dependency: Creating the Vector Store with Dense Embeddings\n",
    "\n",
    "Next, we embed these chunks using OpenAI's `text-embedding-3-small` model and index them in a ChromaDB vector store. This store will power our baseline retriever, which performs a simple semantic similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "part2-2-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating baseline vector store...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "print(\"Creating baseline vector store...\")\n",
    "embedding_function = OpenAIEmbeddings(model=config['embedding_model'], tiktoken_enabled=False, chunk_size=64)\n",
    "\n",
    "# baseline_vector_store = Chroma.from_documents(\n",
    "#     collection_name=\"nvidia-risk\",\n",
    "#     persist_directory=\"./vector_store\",\n",
    "#     documents=doc_chunks,\n",
    "#     embedding=embedding_function,\n",
    "\n",
    "# )\n",
    "# baseline_vector_store = Chroma(\"nvidia-risk\", embedding_function, persist_directory=\"./vector_store\")\n",
    "# baseline_retriever = baseline_vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# print(f\"Vector store created with {baseline_vector_store._collection.count()} embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-3-dep-pro",
   "metadata": {},
   "source": [
    "### 2.3. Code Dependency: Assembling the Simple RAG Chain\n",
    "\n",
    "We use the LangChain Expression Language (LCEL) to construct our linear pipeline. The `RunnablePassthrough` allows us to pass the original question alongside the retrieved context into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "part2-3-code-pro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# template = \"\"\"You are an AI financial analyst. Answer the question based only on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "# llm = ChatOpenAI(model=config[\"fast_llm\"], temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# baseline_rag_chain = (\n",
    "#     {\"context\": baseline_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "# print(\"Baseline RAG chain assembled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-4-fail-pro-adv",
   "metadata": {},
   "source": [
    "### 2.4. The Critical Failure Case: Demonstrating the Need for Advanced Techniques\n",
    "\n",
    "Now we execute our multi-source query against the baseline system. The retriever will attempt to find chunks that match the 'average' semantic meaning of the entire query. This will fail spectacularly because critical information (about AMD's 2024 strategy) does not exist in its knowledge base (the 2023 10-K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "part2-4-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing complex query on the baseline RAG chain...\n"
     ]
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = Console()\n",
    "\n",
    "complex_query_adv = \"Based on NVIDIA's 2023 10-K filing, identify their key risks related to competition. Then, find recent news (post-filing, from 2024) about AMD's AI chip strategy and explain how this new strategy directly addresses or exacerbates one of NVIDIA's stated risks.\"\n",
    "\n",
    "print(\"Executing complex query on the baseline RAG chain...\")\n",
    "# baseline_result = baseline_rag_chain.invoke(complex_query_adv)\n",
    "\n",
    "# console.print(\"--- BASELINE RAG FAILED OUTPUT ---\")\n",
    "# console.print(Markdown(baseline_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-5-diag-pro-adv",
   "metadata": {},
   "source": [
    "### 2.5. Diagnosis: Why Did It Fail?\n",
    "\n",
    "The output is a classic failure case for RAG systems confined to a static knowledge base.\n",
    "\n",
    "1.  **Irrelevant Context:** The retriever, trying to satisfy all parts of the query at once, likely pulled chunks related to \"competition\" and \"AMD\" from the 10-K, but this information is general and lacks the specifics required.\n",
    "2.  **Missing Information:** The 2023 filing **cannot** contain information about events in 2024. The baseline system has no mechanism to access external, up-to-date knowledge.\n",
    "3.  **No Synthesis:** The system correctly states that it lacks the required information. It cannot perform the requested synthesis because it failed to retrieve one of the two necessary pieces of evidence. It lacks any mechanism to recognize this gap and use a different tool (like web search) to fill it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-intro-deep-pro",
   "metadata": {},
   "source": [
    "## Part 3: The \"Deep Thinking\" Upgrade: Engineering an Autonomous Reasoning Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-1-state-pro-adv",
   "metadata": {},
   "source": [
    "### 3.1. Code Dependency: Defining the `RAGState` - The Central Nervous System of Our Agent\n",
    "\n",
    "To build our reasoning agent, we first need a robust way to manage its state. The `RAGState` `TypedDict` will serve as the central nervous system for our agent. It will be passed between every node in our LangGraph workflow, allowing the agent to maintain a coherent line of reasoning, track its progress, and build a comprehensive base of evidence over multiple steps. We will now enhance our `Step` Pydantic model to include a `tool` field, which will be crucial for routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "part3-1-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGState and supporting Pydantic classes defined successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic model for a single step in the reasoning plan\n",
    "class Step(BaseModel):\n",
    "    sub_question: str = Field(description=\"A specific, answerable question for this step.\")\n",
    "    justification: str = Field(description=\"A brief explanation of why this step is necessary to answer the main query.\")\n",
    "    tool: Literal[\"search_10k\", \"search_web\"] = Field(description=\"The tool to use for this step.\")\n",
    "    keywords: List[str] = Field(description=\"A list of critical keywords for searching relevant document sections.\")\n",
    "    document_section: Optional[str] = Field(description=\"A likely document section title (e.g., 'Item 1A. Risk Factors') to search within. Only for 'search_10k' tool.\")\n",
    "\n",
    "# Pydantic model for the overall plan\n",
    "class Plan(BaseModel):\n",
    "    steps: List[Step] = Field(description=\"A detailed, multi-step plan to answer the user's query.\")\n",
    "\n",
    "# TypedDict for storing the results of a completed step\n",
    "class PastStep(TypedDict):\n",
    "    step_index: int\n",
    "    sub_question: str\n",
    "    retrieved_docs: List[Document]\n",
    "    summary: str\n",
    "\n",
    "# The main state dictionary that will flow through the graph\n",
    "class RAGState(TypedDict):\n",
    "    original_question: str\n",
    "    plan: Plan\n",
    "    past_steps: List[PastStep]\n",
    "    current_step_index: int\n",
    "    retrieved_docs: List[Document]\n",
    "    reranked_docs: List[Document]\n",
    "    synthesized_context: str\n",
    "    final_answer: str\n",
    "\n",
    "print(\"RAGState and supporting Pydantic classes defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-2-planner-pro-adv",
   "metadata": {},
   "source": [
    "### 3.2. Component 1: Dynamic Planning and Query Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-2-1-planner-pro-adv",
   "metadata": {},
   "source": [
    "#### 3.2.1. The Tool-Aware Planner Agent: Decomposing the user query and selecting the right tool for each step.\n",
    "\n",
    "The first cognitive act of our agent is to **plan**. We upgrade our 'Planner Agent' to be **tool-aware**. Its sole responsibility is to take the complex user query and decompose it into a structured, multi-step `Plan` object. Crucially, for each step, it must now decide whether the information is likely to be in the static document (`search_10k`) or requires up-to-date, external information (`search_web`). This decision-making at the planning stage is fundamental to the agent's intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "part3-2-1-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool-Aware Planner Agent created successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from rich.pretty import pprint as rprint\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert research planner. Your task is to create a clear, multi-step plan to answer a complex user query by retrieving information from multiple sources.\n",
    "You have two tools available:\n",
    "1. `search_10k`: Use this to search for information within NVIDIA's 2023 10-K financial filing. This is best for historical facts, financial data, and stated company policies or risks from that specific time period.\n",
    "2. `search_web`: Use this to search the public internet for recent news, competitor information, or any topic that is not specific to NVIDIA's 2023 10-K.\n",
    "\n",
    "Decompose the user's query into a series of simple, sequential sub-questions. For each step, decide which tool is more appropriate.\n",
    "For `search_10k` steps, also identify the most likely section of the 10-K (e.g., 'Item 1A. Risk Factors', 'Item 7. Management’s Discussion and Analysis...').\n",
    "It is critical to use the exact section titles found in a 10-K filing where possible.\"\"\"),\n",
    "    (\"human\", \"User Query: {question}\")\n",
    "])\n",
    "\n",
    "reasoning_llm = ChatOpenAI(model=config[\"reasoning_llm\"], temperature=0)\n",
    "planner_agent = planner_prompt | reasoning_llm.with_structured_output(Plan)\n",
    "print(\"Tool-Aware Planner Agent created successfully.\")\n",
    "\n",
    "# Test the planner agent\n",
    "# print(\"--- Testing Planner Agent ---\")\n",
    "# test_plan = planner_agent.invoke({\"question\": complex_query_adv})\n",
    "# rprint(test_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-2-2-rewriter-pro",
   "metadata": {},
   "source": [
    "#### 3.2.2. Query Rewriting and Expansion: Using an LLM to transform naive sub-questions into high-quality search queries.\n",
    "\n",
    "A sub-question from the plan (e.g., \"What are the risks?\") might not be the optimal query for a vector database or web search engine. We create a 'Query Rewriter' agent that enriches the sub-question with keywords from the plan and context from previous steps, making it a much more effective search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "part3-2-2-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Rewriter Agent created successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "query_rewriter_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a search query optimization expert. Your task is to rewrite a given sub-question into a highly effective search query for a vector database or web search engine, using keywords and context from the research plan.\n",
    "The rewritten query should be specific, use terminology likely to be found in the target source (a financial 10-K or news articles), and be structured to retrieve the most relevant text snippets.\"\"\"),\n",
    "    (\"human\", \"Current sub-question: {sub_question}\\n\\nRelevant keywords from plan: {keywords}\\n\\nContext from past steps:\\n{past_context}\")\n",
    "])\n",
    "\n",
    "query_rewriter_agent = query_rewriter_prompt | reasoning_llm | StrOutputParser()\n",
    "print(\"Query Rewriter Agent created successfully.\")\n",
    "\n",
    "# Test the rewriter agent\n",
    "# print(\"--- Testing Query Rewriter Agent ---\")\n",
    "# test_sub_q = test_plan.steps[2] # The synthesis step\n",
    "# test_past_context = \"Step 1 Summary: NVIDIA's 10-K lists intense competition and rapid technological change as key risks. Step 2 Summary: AMD launched its MI300X AI accelerator in 2024 to directly compete with NVIDIA's H100.\"\n",
    "# rewritten_q = query_rewriter_agent.invoke({\n",
    "#     \"sub_question\": test_sub_q.sub_question,\n",
    "#     \"keywords\": test_sub_q.keywords,\n",
    "#     \"past_context\": test_past_context\n",
    "# })\n",
    "# print(f\"Original sub-question: {test_sub_q.sub_question}\")\n",
    "# print(f\"Rewritten Search Query: {rewritten_q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-2-3-metadata-pro",
   "metadata": {},
   "source": [
    "#### 3.2.3. Entity and Constraint Extraction: Identifying metadata filters to enable filtered vector search.\n",
    "\n",
    "This is a crucial step for precision when using the `search_10k` tool. Our planner already extracts the likely `document_section`. To use this, we need to re-process our documents, adding this section title as metadata to each chunk. This allows us to perform a *filtered search*, telling the vector store to *only* search within chunks that have the correct metadata (e.g., only search for risks in the 'Risk Factors' section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "part3-2-3-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document and adding metadata...\n",
      "Identified 1 document sections.\n",
      "Created 42 chunks with section metadata.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing document and adding metadata...\")\n",
    "# Regex to match the 'Item X' and 'Item X.Y' patterns for section titles\n",
    "section_pattern = r\"(ITEM\\s+\\d[A-Z]?\\.\\s*.*?)(?=\\nITEM\\s+\\d[A-Z]?\\.|$)\"\n",
    "raw_text = documents[0].page_content\n",
    "\n",
    "# Find all matches for section titles\n",
    "section_titles = re.findall(section_pattern, raw_text, re.IGNORECASE | re.DOTALL)\n",
    "section_titles = [title.strip().replace('\\n', ' ') for title in section_titles]\n",
    "\n",
    "# Split the document content by these titles\n",
    "sections_content = re.split(section_pattern, raw_text, flags=re.IGNORECASE | re.DOTALL)\n",
    "sections_content = [content.strip() for content in sections_content if content.strip() and not content.strip().lower().startswith('item ')]\n",
    "\n",
    "print(f\"Identified {len(section_titles)} document sections.\")\n",
    "assert len(section_titles) == len(sections_content), \"Mismatch between titles and content sections\"\n",
    "\n",
    "doc_chunks_with_metadata = []\n",
    "for i, content in enumerate(sections_content):\n",
    "    section_title = section_titles[i]\n",
    "    # Chunk the content of this specific section\n",
    "    section_chunks = text_splitter.split_text(content)\n",
    "    for chunk in section_chunks:\n",
    "        chunk_id = str(uuid.uuid4())\n",
    "        doc_chunks_with_metadata.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"section\": section_title,\n",
    "                    \"source_doc\": doc_path_clean,\n",
    "                    \"id\": chunk_id\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Created {len(doc_chunks_with_metadata)} chunks with section metadata.\")\n",
    "# print(\"--- Sample Chunk with Metadata ---\")\n",
    "# sample_chunk = next(c for c in doc_chunks_with_metadata if \"Risk Factors\" in c.metadata.get(\"section\", \"\"))\n",
    "# rprint(sample_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-3-retrieval-pro-adv",
   "metadata": {},
   "source": [
    "### 3.3. Component 2: The Multi-Stage, Adaptive Retrieval Funnel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-3-1-supervisor-pro",
   "metadata": {},
   "source": [
    "#### 3.3.1. NEW: The Retrieval Supervisor Agent\n",
    "\n",
    "This is a new, crucial component for intelligent retrieval. Not all questions are created equal. Some benefit from semantic search (e.g., \"What are the company's feelings on climate change?\"), while others are better with keyword search (e.g., \"What was the revenue for the 'Compute & Networking' segment?\").\n",
    "\n",
    "The **Retrieval Supervisor** is a small LLM agent that acts as a router. For each `search_10k` step, it analyzes the sub-question and decides which retrieval strategy—`vector_search`, `keyword_search`, or `hybrid_search`—is most appropriate. This adds a layer of dynamic decision-making that optimizes the retrieval process for each specific query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "part3-3-1-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Supervisor Agent created.\n"
     ]
    }
   ],
   "source": [
    "class RetrievalDecision(BaseModel):\n",
    "    strategy: Literal[\"vector_search\", \"keyword_search\", \"hybrid_search\"]\n",
    "    justification: str\n",
    "\n",
    "retrieval_supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a retrieval strategy expert. Based on the user's query, you must decide the best retrieval strategy.\n",
    "You have three options:\n",
    "1. `vector_search`: Best for conceptual, semantic, or similarity-based queries.\n",
    "2. `keyword_search`: Best for queries with specific, exact terms, names, or codes (e.g., 'Item 1A', 'Hopper architecture').\n",
    "3. `hybrid_search`: A good default that combines both, but may be less precise than a targeted strategy.\"\"\"),\n",
    "    (\"human\", \"User Query: {sub_question}\")\n",
    "])\n",
    "\n",
    "retrieval_supervisor_agent = retrieval_supervisor_prompt | reasoning_llm.with_structured_output(RetrievalDecision)\n",
    "print(\"Retrieval Supervisor Agent created.\")\n",
    "\n",
    "# Test the supervisor\n",
    "# print(\"--- Testing Retrieval Supervisor Agent ---\")\n",
    "# query1 = \"revenue growth for the Compute & Networking segment in fiscal year 2023\"\n",
    "# decision1 = retrieval_supervisor_agent.invoke({\"sub_question\": query1})\n",
    "# print(f\"Query: '{query1}'\")\n",
    "# print(f\"Decision: {decision1.strategy}, Justification: {decision1.justification}\")\n",
    "\n",
    "# query2 = \"general sentiment about market competition and technological innovation\"\n",
    "# decision2 = retrieval_supervisor_agent.invoke({\"sub_question\": query2})\n",
    "# print(f\"Query: '{query2}'\")\n",
    "# print(f\"Decision: {decision2.strategy}, Justification: {decision2.justification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-3-2-strategies-pro",
   "metadata": {},
   "source": [
    "#### 3.3.2. Implementing the Retrieval Strategies\n",
    "\n",
    "Now we build our advanced retriever. We create a new vector store with our metadata-rich chunks. We then implement three distinct search functions: pure vector search, pure keyword search (BM25), and a hybrid approach that fuses the results using Reciprocal Rank Fusion (RRF). Our `retrieval_node` in the graph will use the decision from the `RetrievalSupervisor` to call the appropriate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part3-3-1-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating advanced vector store with metadata...\n",
      "Advanced vector store created with 42 embeddings.\n",
      "Building BM25 index for keyword search...\n",
      "All retrieval strategy functions ready.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "print(\"Creating advanced vector store with metadata...\")\n",
    "# advanced_vector_store = Chroma.from_documents(\n",
    "#     documents=doc_chunks_with_metadata,\n",
    "#     embedding=embedding_function,\n",
    "#     collection_name=\"nvidia-risk\", \n",
    "#     persist_directory=\"./vector_store\",\n",
    "# )\n",
    "advanced_vector_store = Chroma(\"nvidia-risk\", embedding_function, persist_directory=\"./vector_store\")\n",
    "print(f\"Advanced vector store created with {advanced_vector_store._collection.count()} embeddings.\")\n",
    "\n",
    "print(\"Building BM25 index for keyword search...\")\n",
    "tokenized_corpus = [doc.page_content.split(\" \") for doc in doc_chunks_with_metadata]\n",
    "doc_ids = [doc.metadata[\"id\"] for doc in doc_chunks_with_metadata]\n",
    "doc_map = {doc.metadata[\"id\"]: doc for doc in doc_chunks_with_metadata}\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def vector_search_only(query: str, section_filter: str = None, k: int = 10):\n",
    "    filter_dict = {\"section\": section_filter} if section_filter and \"Unknown\" not in section_filter else None\n",
    "    return advanced_vector_store.similarity_search(query, k=k, filter=filter_dict)\n",
    "\n",
    "def bm25_search_only(query: str, k: int = 10):\n",
    "    tokenized_query = query.split(\" \")\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    top_k_indices = np.argsort(bm25_scores)[::-1][:k]\n",
    "    return [doc_map[doc_ids[i]] for i in top_k_indices]\n",
    "\n",
    "def hybrid_search(query: str, section_filter: str = None, k: int = 10):\n",
    "    # 1. Keyword Search (BM25)\n",
    "    bm25_docs = bm25_search_only(query, k=k)\n",
    "\n",
    "    # 2. Semantic Search (with metadata filtering)\n",
    "    semantic_docs = vector_search_only(query, section_filter=section_filter, k=k)\n",
    "\n",
    "    # 3. Reciprocal Rank Fusion (RRF)\n",
    "    all_docs = {doc.metadata[\"id\"]: doc for doc in bm25_docs + semantic_docs}.values()\n",
    "    ranked_lists = [[doc.metadata[\"id\"] for doc in bm25_docs], [doc.metadata[\"id\"] for doc in semantic_docs]]\n",
    "    \n",
    "    rrf_scores = {}\n",
    "    for doc_list in ranked_lists:\n",
    "        for i, doc_id in enumerate(doc_list):\n",
    "            if doc_id not in rrf_scores:\n",
    "                rrf_scores[doc_id] = 0\n",
    "            rrf_scores[doc_id] += 1 / (i + 61) # RRF rank constant k = 60\n",
    "\n",
    "    sorted_doc_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)\n",
    "    final_docs = [doc_map[doc_id] for doc_id in sorted_doc_ids[:k]]\n",
    "    return final_docs\n",
    "\n",
    "print(\"All retrieval strategy functions ready.\")\n",
    "\n",
    "# Test Keyword Search\n",
    "# print(\"--- Testing Keyword Search ---\")\n",
    "# test_query = \"Item 1A. Risk Factors\"\n",
    "# test_results = bm25_search_only(test_query)\n",
    "# print(f\"Query: {test_query}\")\n",
    "# print(f\"Found {len(test_results)} documents. Top result section: {test_results[0].metadata['section']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.re import BM25Retriever, EnsembleRetriever\n",
    "# 准备文档内容（BM25 需要原始文本） \n",
    "doc_texts = [doc.page_content for doc in chunks]\n",
    "# # 创建 BM25 检索器 \n",
    "retriever_bm25 = BM25Retriever.from_texts(doc_texts, metadatas=[doc.metadata for doc in chunks]) \n",
    "retriever_bm25.k = 3\n",
    "# 返回前 3 个结果  # 创建混合检索器 \n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vector, retriever_bm25],\n",
    "                                       weights=[0.6,0.4] # 向量检索权重 0.6，BM25 权重 0.4 \n",
    ")\n",
    "# 测试混合检索 \n",
    "query =\"PostgreSQL 索引优化\" \n",
    "results_hybrid = ensemble_retriever.get_relevant_documents(query)\n",
    "print(f\"混合检索结果：\")\n",
    "for i, doc in enumerate(results_hybrid, 1): \n",
    "  print(f\"{i}.{doc.page_content[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-3-3-reranker-pro",
   "metadata": {},
   "source": [
    "#### 3.3.3. Stage 2 (High Precision): Cross-Encoder Reranker.\n",
    "\n",
    "After retrieving a broad set of `k` documents, we use a more computationally expensive but far more accurate **Cross-Encoder** model. Unlike embedding models (bi-encoders) that create vectors independently, a cross-encoder processes the query and each document *together*, yielding a much more nuanced relevance score. This allows us to re-rank the `k` candidates and select the top `n` with high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "part3-3-2-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CrossEncoder reranker...\n",
      "Cross-Encoder ready.\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import CrossEncoder\n",
    "import requests\n",
    "\n",
    "print(\"Initializing CrossEncoder reranker...\")\n",
    "# reranker = CrossEncoder(config[\"reranker_model\"])\n",
    "\n",
    "def rerank_documents_function(query: str, documents: List[Document]) -> List[Document]:\n",
    "    if not documents: return []\n",
    "    # pairs = [(query, doc.page_content) for doc in documents]\n",
    "    # scores = reranker.predict(pairs)\n",
    "    # Combine documents with their scores and sort\n",
    "    # doc_scores = list(zip(documents, scores))\n",
    "    # doc_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N documents\n",
    "    # reranked_docs = [doc for doc, score in doc_scores[:config[\"top_n_rerank\"]]]\n",
    "\n",
    "\n",
    "    url = \"https://api.siliconflow.cn/v1/rerank\"\n",
    "    pairs = [doc.page_content for doc in documents]\n",
    "    payload = {\n",
    "        \"model\": \"BAAI/bge-reranker-v2-m3\",\n",
    "        \"query\": query,\n",
    "        \"documents\": pairs,\n",
    "        \"instruction\": \"Please rerank the documents based on the query.\",\n",
    "        \"return_documents\": True,\n",
    "        \"max_chunks_per_doc\": 123,\n",
    "        \"overlap_tokens\": 79\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    data = response.json()\n",
    "    ranked_results = data[\"results\"]\n",
    "    reranked_docs = [documents[doc[\"index\"]] for doc in ranked_results]\n",
    "    return reranked_docs[:config[\"top_n_rerank\"]]\n",
    "\n",
    "print(\"Cross-Encoder ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-3-4-distill-pro",
   "metadata": {},
   "source": [
    "#### 3.3.4. Stage 3 (Contextual Distillation): Implementing logic to synthesize a concise context.\n",
    "\n",
    "The final step in our retrieval funnel is to distill the top `n` highly relevant chunks into a single, clean paragraph of context. This removes redundancy and presents the information to the downstream agents in a clean, easy-to-process format. We create a dedicated 'Distiller Agent' for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "part3-3-3-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual Distiller Agent created.\n"
     ]
    }
   ],
   "source": [
    "distiller_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant. Your task is to synthesize the following retrieved document snippets into a single, concise paragraph.\n",
    "The goal is to provide a clear and coherent context that directly answers the question: '{question}'.\n",
    "Focus on removing redundant information and organizing the content logically. Answer only with the synthesized context.\"\"\"),\n",
    "    (\"human\", \"Retrieved Documents:\\n{context}\")\n",
    "])\n",
    "\n",
    "distiller_agent = distiller_prompt | reasoning_llm | StrOutputParser()\n",
    "print(\"Contextual Distiller Agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-4-tool-pro",
   "metadata": {},
   "source": [
    "### 3.4. Component 3: Tool Augmentation with Web Search\n",
    "\n",
    "To answer questions about recent events or competitors, our agent needs to break out of its static knowledge base. We equip it with a web search tool using the Tavily Search API. The `planner_agent` will decide when to invoke this tool. The results from the web search will be formatted into LangChain `Document` objects, allowing them to be processed by the same reranking and compression pipeline as the documents retrieved from our vector store. This ensures a seamless integration of internal and external knowledge sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "part3-4-code-pro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web search tool (Tavily) initialized.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "def web_search_function(query: str) -> List[Document]:\n",
    "    results = web_search_tool.invoke({\"query\": query})\n",
    "    console.print(results)\n",
    "    return [Document(page_content=res[\"content\"], metadata={\"source\": res[\"url\"]}) for res in results if isinstance(res, dict)]\n",
    "\n",
    "print(\"Web search tool (Tavily) initialized.\")\n",
    "\n",
    "# Test the web search\n",
    "# print(\"--- Testing Web Search Tool ---\")\n",
    "# test_query_web = \"AMD AI chip strategy 2024\"\n",
    "# test_results_web = web_search_function(test_query_web)\n",
    "# print(f\"Found {len(test_results_web)} results for query: '{test_query_web}'\")\n",
    "# if test_results_web:\n",
    "#     print(f\"Top result snippet: {test_results_web[0].page_content[:250]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-5-critique-pro",
   "metadata": {},
   "source": [
    "### 3.5. Component 4: The Self-Critique and Control Flow Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-5-1-reflect-pro",
   "metadata": {},
   "source": [
    "#### 3.5.1. The \"Update and Reflect\" Step: An agent that synthesizes new findings into the `RAGState`'s reasoning history.\n",
    "\n",
    "After each retrieval loop, the agent needs to integrate its new knowledge. The 'Reflection Agent' takes the distilled context from the current step and creates a concise summary. This summary is then appended to the `past_steps` list in our `RAGState`, forming a cumulative log of the agent's research journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "part3-4-1-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection Agent created.\n"
     ]
    }
   ],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a research assistant. Based on the retrieved context for the current sub-question, write a concise, one-sentence summary of the key findings.\n",
    "This summary will be added to our research history. Be factual and to the point.\"\"\"),\n",
    "    (\"human\", \"Current sub-question: {sub_question}\\n\\nDistilled context:\\n{context}\")\n",
    "])\n",
    "reflection_agent = reflection_prompt | reasoning_llm | StrOutputParser()\n",
    "print(\"Reflection Agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-5-2-policy-pro",
   "metadata": {},
   "source": [
    "#### 3.5.2. Policy Implementation (LLM-as-a-Judge): Prompting an LLM to inspect the current state and decide the next action.\n",
    "\n",
    "This is the cognitive core of our agent's autonomy. The 'Policy Agent' acts as a supervisor. After each reflection step, it examines the *entire* research history (`past_steps`) in relation to the original question and the plan. It then makes a structured decision: `CONTINUE_PLAN` if more information is needed, or `FINISH` if the question has been comprehensively answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "part3-4-2-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Agent created.\n"
     ]
    }
   ],
   "source": [
    "class Decision(BaseModel):\n",
    "    next_action: Literal[\"CONTINUE_PLAN\", \"FINISH\"]\n",
    "    justification: str\n",
    "\n",
    "policy_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a master strategist. Your role is to analyze the research progress and decide the next action.\n",
    "You have the original question, the initial plan, and a log of completed steps with their summaries.\n",
    "- If the collected information in the Research History is sufficient to comprehensively answer the Original Question, decide to FINISH.\n",
    "- Otherwise, if the plan is not yet complete, decide to CONTINUE_PLAN.\"\"\"),\n",
    "    (\"human\", \"Original Question: {question}\\n\\nInitial Plan:\\n{plan}\\n\\nResearch History (Completed Steps):\\n{history}\")\n",
    "])\n",
    "policy_agent = policy_prompt | reasoning_llm.with_structured_output(Decision)\n",
    "print(\"Policy Agent created.\")\n",
    "\n",
    "# Test the policy agent with different states\n",
    "# plan_str = json.dumps([s.dict() for s in test_plan.steps])\n",
    "# incomplete_history = \"Step 1 Summary: NVIDIA's 10-K states that the semiconductor industry is intensely competitive and subject to rapid technological change.\"\n",
    "# decision1 = policy_agent.invoke({\"question\": complex_query_adv, \"plan\": plan_str, \"history\": incomplete_history})\n",
    "# print(\"--- Testing Policy Agent (Incomplete State) ---\")\n",
    "# print(f\"Decision: {decision1.next_action}, Justification: {decision1.justification}\")\n",
    "\n",
    "# complete_history = incomplete_history + \"\\nStep 2 Summary: In 2024, AMD launched its MI300X accelerator to directly compete with NVIDIA in the AI chip market, gaining adoption from major cloud providers.\"\n",
    "# decision2 = policy_agent.invoke({\"question\": complex_query_adv, \"plan\": plan_str, \"history\": complete_history})\n",
    "# print(\"--- Testing Policy Agent (Complete State) ---\")\n",
    "# print(f\"Decision: {decision2.next_action}, Justification: {decision2.justification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-5-3-stopping-pro",
   "metadata": {},
   "source": [
    "#### 3.5.3. Defining Robust Stopping Criteria\n",
    "\n",
    "Our system needs clear and robust conditions to stop the reasoning loop. We have three such criteria:\n",
    "1.  **Policy Decision:** The primary stopping condition is when the `policy_agent` confidently decides to `FINISH`.\n",
    "2.  **Plan Completion:** If the agent has executed every step in its plan, it will naturally conclude its work.\n",
    "3.  **Max Iterations:** As a safeguard against infinite loops or runaway processes, we enforce a hard limit (`max_reasoning_iterations` from our config) on the number of research cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-intro-graph-pro",
   "metadata": {},
   "source": [
    "## Part 4: Assembly with LangGraph - Orchestrating the Reasoning Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-1-nodes-pro-adv",
   "metadata": {},
   "source": [
    "### 4.1. Code Dependency: Defining the Graph Nodes\n",
    "\n",
    "Now, we translate our conceptual components into concrete graph nodes. Each node is a Python function that accepts the `RAGState` dictionary, performs its designated task, and returns a dictionary containing the state updates. We add a new `web_search_node` to handle the external search tool, and we modify the `retrieval_node` to incorporate the adaptive strategy chosen by our new Supervisor agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "part4-1-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All graph nodes defined successfully.\n"
     ]
    }
   ],
   "source": [
    "def get_past_context_str(past_steps: List[PastStep]) -> str:\n",
    "    return \"\\n\\n\".join([f\"Step {s['step_index']}: {s['sub_question']}\\nSummary: {s['summary']}\" for s in past_steps])\n",
    "\n",
    "def plan_node(state: RAGState) -> Dict:\n",
    "    console.print(\"--- 🧠: Generating Plan ---\")\n",
    "    plan = planner_agent.invoke({\"question\": state[\"original_question\"]})\n",
    "    rprint(plan)\n",
    "    return {\"plan\": plan, \"current_step_index\": 0, \"past_steps\": []}\n",
    "\n",
    "def plan_next_node(state: RAGState) -> Dict:\n",
    "    return {}\n",
    "\n",
    "def retrieval_node(state: RAGState) -> Dict:\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    current_step = state[\"plan\"].steps[current_step_index]\n",
    "    console.print(f\"--- 🔍: Retrieving from 10-K (Step {current_step_index + 1}: {current_step.sub_question}) ---\")\n",
    "    past_context = get_past_context_str(state['past_steps'])\n",
    "    rewritten_query = query_rewriter_agent.invoke({\n",
    "        \"sub_question\": current_step.sub_question,\n",
    "        \"keywords\": current_step.keywords,\n",
    "        \"past_context\": past_context\n",
    "    })\n",
    "    console.print(f\"  Rewritten Query: {rewritten_query}\")\n",
    "    \n",
    "    # NEW: Adaptive Retrieval Strategy\n",
    "    retrieval_decision = retrieval_supervisor_agent.invoke({\"sub_question\": rewritten_query})\n",
    "    console.print(f\"  Supervisor Decision: Use `{retrieval_decision.strategy}`. Justification: {retrieval_decision.justification}\")\n",
    "\n",
    "    if retrieval_decision.strategy == 'vector_search':\n",
    "        retrieved_docs = vector_search_only(rewritten_query, section_filter=current_step.document_section, k=config['top_k_retrieval'])\n",
    "    elif retrieval_decision.strategy == 'keyword_search':\n",
    "        retrieved_docs = bm25_search_only(rewritten_query, k=config['top_k_retrieval'])\n",
    "    else: # hybrid_search\n",
    "        retrieved_docs = hybrid_search(rewritten_query, section_filter=current_step.document_section, k=config['top_k_retrieval'])\n",
    "    \n",
    "    return {\"retrieved_docs\": retrieved_docs}\n",
    "\n",
    "def web_search_node(state: RAGState) -> Dict:\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    current_step = state[\"plan\"].steps[current_step_index]\n",
    "    console.print(f\"--- 🌐: Searching Web (Step {current_step_index + 1}: {current_step.sub_question}) ---\")\n",
    "    past_context = get_past_context_str(state['past_steps'])\n",
    "    rewritten_query = query_rewriter_agent.invoke({\n",
    "        \"sub_question\": current_step.sub_question,\n",
    "        \"keywords\": current_step.keywords,\n",
    "        \"past_context\": past_context\n",
    "    })\n",
    "    console.print(f\"  Rewritten Query: {rewritten_query}\")\n",
    "    retrieved_docs = web_search_function(rewritten_query)\n",
    "    return {\"retrieved_docs\": retrieved_docs}\n",
    "\n",
    "def rerank_node(state: RAGState) -> Dict:\n",
    "    console.print(\"--- 🎯: Reranking Documents ---\")\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    current_step = state[\"plan\"].steps[current_step_index]\n",
    "    reranked_docs = rerank_documents_function(current_step.sub_question, state[\"retrieved_docs\"])\n",
    "    console.print(f\"  Reranked to top {len(reranked_docs)} documents.\")\n",
    "    return {\"reranked_docs\": reranked_docs}\n",
    "\n",
    "def compression_node(state: RAGState) -> Dict:\n",
    "    console.print(\"--- ✂️: Distilling Context ---\")\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    current_step = state[\"plan\"].steps[current_step_index]\n",
    "    context = format_docs(state[\"reranked_docs\"])\n",
    "    synthesized_context = distiller_agent.invoke({\"question\": current_step.sub_question, \"context\": context})\n",
    "    console.print(f\"  Distilled Context Snippet: {synthesized_context[:200]}...\")\n",
    "    return {\"synthesized_context\": synthesized_context}\n",
    "\n",
    "def  reflection_node(state: RAGState) -> Dict:\n",
    "    console.print(\"--- 🤔: Reflecting on Findings ---\")\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    current_step = state[\"plan\"].steps[current_step_index]\n",
    "    summary = reflection_agent.invoke({\"sub_question\": current_step.sub_question, \"context\": state['synthesized_context']})\n",
    "    console.print(f\"  Summary: {summary}\")\n",
    "    new_past_step = {\n",
    "        \"step_index\": current_step_index + 1,\n",
    "        \"sub_question\": current_step.sub_question,\n",
    "        \"retrieved_docs\": state['reranked_docs'],\n",
    "        \"summary\": summary\n",
    "    }\n",
    "    return {\"past_steps\": state[\"past_steps\"] + [new_past_step], \"current_step_index\": current_step_index + 1}\n",
    "\n",
    "def final_answer_node(state: RAGState) -> Dict:\n",
    "    console.print(\"--- ✅: Generating Final Answer with Citations ---\")\n",
    "    # Create a consolidated context with metadata for citation\n",
    "    final_context = \"\"\n",
    "    for i, step in enumerate(state['past_steps']):\n",
    "        final_context += f\"\\n--- Findings from Research Step {i+1} ---\\n\"\n",
    "        for doc in step['retrieved_docs']:\n",
    "            source = doc.metadata.get('section') or doc.metadata.get('source')\n",
    "            final_context += f\"Source: {source}\\nContent: {doc.page_content}\\n\\n\"\n",
    "    \n",
    "    final_answer_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert financial analyst. Synthesize the research findings from internal documents and web searches into a comprehensive, multi-paragraph answer for the user's original question.\n",
    "Your answer must be grounded in the provided context. At the end of any sentence that relies on specific information, you MUST add a citation. For 10-K documents, use [Source: <section title>]. For web results, use [Source: <URL>].\"\"\"),\n",
    "        (\"human\", \"Original Question: {question}\\n\\nResearch History and Context:\\n{context}\")\n",
    "    ])\n",
    "    \n",
    "    final_answer_agent = final_answer_prompt | reasoning_llm | StrOutputParser()\n",
    "    final_answer = final_answer_agent.invoke({\"question\": state['original_question'], \"context\": final_context})\n",
    "    return {\"final_answer\": final_answer}\n",
    "\n",
    "print(\"All graph nodes defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-2-edges-pro-adv",
   "metadata": {},
   "source": [
    "### 4.2. Code Dependency: Defining the Conditional Edges - Implementing the Self-Critique Policy Logic\n",
    "\n",
    "We now define the logic that controls the flow of our graph. We add a `route_by_tool` function that checks the plan and directs the agent to either the `retrieval_node` or the `web_search_node`. The `should_continue_node` remains the primary controller for the main reasoning loop, implementing our stopping criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "part4-2-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional edge logic functions defined.\n"
     ]
    }
   ],
   "source": [
    "def route_by_tool(state: RAGState) -> str:\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    current_step = state[\"plan\"].steps[current_step_index]\n",
    "    return current_step.tool\n",
    "\n",
    "def should_continue_node(state: RAGState) -> str:\n",
    "    console.print(\"--- 🚦: Evaluating Policy ---\")\n",
    "    current_step_index = state[\"current_step_index\"]\n",
    "    \n",
    "    if current_step_index >= len(state[\"plan\"].steps):\n",
    "        console.print(\"  -> Plan complete. Finishing.\")\n",
    "        return \"finish\"\n",
    "    \n",
    "    if current_step_index >= config[\"max_reasoning_iterations\"]:\n",
    "        console.print(\"  -> Max iterations reached. Finishing.\")\n",
    "        return \"finish\"\n",
    "\n",
    "    # Check if the last retrieval step failed to find documents\n",
    "    if not state[\"reranked_docs\"]:\n",
    "        console.print(\"  -> Retrieval failed for the last step. Continuing with next step in plan.\")\n",
    "        return \"continue\"\n",
    "\n",
    "    history = get_past_context_str(state['past_steps'])\n",
    "    plan_str = json.dumps([s.dict() for s in state['plan'].steps])\n",
    "    decision = policy_agent.invoke({\"question\": state[\"original_question\"], \"plan\": plan_str, \"history\": history})\n",
    "    console.print(f\"  -> Decision: {decision.next_action} | Justification: {decision.justification}\")\n",
    "    \n",
    "    if decision.next_action == \"FINISH\":\n",
    "        return \"finish\"\n",
    "    else: # CONTINUE_PLAN\n",
    "        return \"continue\"\n",
    "\n",
    "print(\"Conditional edge logic functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-3-build-pro-adv",
   "metadata": {},
   "source": [
    "### 4.3. Building the `StateGraph`: Wiring the Deep Thinking RAG Machine\n",
    "\n",
    "Now we instantiate the `StateGraph` and assemble our more advanced cognitive architecture. The key change is adding a conditional entry point after the `plan` node. This `route_by_tool` edge will direct the agent to the correct tool for the current step. After each tool execution and subsequent processing, the graph flows to the `reflect` node, which then loops back to the tool router for the next step in the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "part4-3-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateGraph constructed successfully.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(RAGState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"plan\", plan_node)\n",
    "graph.add_node(\"retrieve_10k\", retrieval_node)\n",
    "graph.add_node(\"retrieve_web\", web_search_node)\n",
    "graph.add_node(\"rerank\", rerank_node)\n",
    "graph.add_node(\"compress\", compression_node)\n",
    "graph.add_node(\"reflect\", reflection_node)\n",
    "graph.add_node(\"generate_final_answer\", final_answer_node)\n",
    "graph.add_node(\"plan_next_node\", plan_next_node)\n",
    "# Define edges\n",
    "graph.set_entry_point(\"plan\")\n",
    "graph.add_conditional_edges(\n",
    "    \"plan\",\n",
    "    route_by_tool,\n",
    "    {\n",
    "        \"search_10k\": \"retrieve_10k\",\n",
    "        \"search_web\": \"retrieve_web\",\n",
    "    },\n",
    ")\n",
    "graph.add_conditional_edges(\"plan_next_node\", \n",
    "    route_by_tool,\n",
    "    {\n",
    "        \"search_10k\": \"retrieve_10k\",\n",
    "        \"search_web\": \"retrieve_web\",\n",
    "    },)\n",
    "\n",
    "graph.add_edge(\"retrieve_10k\", \"rerank\")\n",
    "graph.add_edge(\"retrieve_web\", \"rerank\")\n",
    "graph.add_edge(\"rerank\", \"compress\")\n",
    "graph.add_edge(\"compress\", \"reflect\")\n",
    "graph.add_conditional_edges(\n",
    "    \"reflect\",\n",
    "    should_continue_node,\n",
    "    {\n",
    "        \"continue\": \"plan_next_node\", # Re-evaluate plan for next step's tool\n",
    "        \"finish\": \"generate_final_answer\",\n",
    "    },\n",
    ")\n",
    "graph.add_edge(\"generate_final_answer\", END)\n",
    "print(\"StateGraph constructed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-4-viz-pro-adv",
   "metadata": {},
   "source": [
    "### 4.4. Compiling and Visualizing the Iterative Workflow\n",
    "\n",
    "The final step is to compile our graph definition into an executable `Runnable`. We then generate a visual diagram of the graph. The new diagram will clearly show the branching logic where the agent decides between its internal knowledge base (`retrieve_10k`) and its external web search tool (`retrieve_web`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "part4-4-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "deep_thinking_rag_graph = graph.compile()\n",
    "print(\"Graph compiled successfully.\")\n",
    "\n",
    "# try:\n",
    "#     from IPython.display import Image, display\n",
    "#     # Correctly call get_graph() before draw_png()\n",
    "#     png_image = deep_thinking_rag_graph.get_graph().draw_png()\n",
    "#     display(Image(png_image))\n",
    "# except Exception as e:\n",
    "#     print(f\"Graph visualization failed: {e}. Please ensure pygraphviz is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-intro-redemption-pro",
   "metadata": {},
   "source": [
    "## Part 5: Redemption - Running the Deep Thinking Pipeline on Our Challenge Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-1-invoke-pro-adv",
   "metadata": {},
   "source": [
    "### 5.1. Invoking the Graph: A Step-by-Step Trace of the Full Reasoning Process\n",
    "\n",
    "With our graph compiled, we can now invoke it with our complex, multi-source query. We use the `.stream()` method to observe the agent's execution in real-time. The trace will now demonstrate the agent's ability to first query its internal knowledge base, and then seamlessly switch to its web search tool to gather the external information required to fully answer the user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "part5-1-code-pro-adv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Invoking Deep Thinking RAG Graph ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🧠: Generating Plan ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🧠: Generating Plan ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Plan</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"What are NVIDIA's key risks related to competition as stated in their 2023 10-K filing?\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The 'Risk Factors' section in a 10-K filing typically outlines the key risks a company faces, including those related to competition. This is the most likely section where NVIDIA would detail its competitive risks.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_10k'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'competition'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rivals'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'market competition'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Intel'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rival companies'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Item 1A. Risk Factors'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Does NVIDIA's 2023 10-K provide any additional context or analysis in the Management's Discussion and Analysis section regarding competitive risks?\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"This section often provides context and analysis of the company's financial performance and strategic outlook, which may include additional insights into competitive dynamics.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_10k'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'competitive landscape'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rival companies'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Intel'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'market position'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"What does NVIDIA's 2023 10-K say about its competitors and the competitive environment in the AI chip market?\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The 'Business' section may describe the company's industry and competitors, offering a broader view of the competitive environment.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_10k'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'industry'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'competitors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Intel'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'market'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Item 1. Business'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"What is AMD's AI chip strategy as reported in recent news (post-2023 10-K filing, from 2024)?\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Recent news about AMD's AI chip strategy is not likely to be found in NVIDIA's 10-K filing. A web search is necessary to find up-to-date information from 2024.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_web'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AI chip strategy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'2024'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recent news'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AI hardware'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'N/A'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Step</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">sub_question</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"How does AMD's 2024 AI chip strategy directly address or exacerbate one of NVIDIA's stated competitive risks from their 2023 10-K filing?\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">justification</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"To determine how AMD's new strategy relates to NVIDIA's stated risks, we need to analyze the recent news in the context of the risks identified in the 10-K. This is a synthesis step and does not require a new search.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_web'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">keywords</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">document_section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'N/A'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlan\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m\"What\u001b[0m\u001b[32m are NVIDIA's key risks related to competition as stated in their 2023 10-K filing?\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m 'Risk Factors' section in a 10-K filing typically outlines the key risks a company faces, including those related to competition. This is the most likely section where NVIDIA would detail its competitive risks.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_10k'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'competition'\u001b[0m, \u001b[32m'rivals'\u001b[0m, \u001b[32m'market competition'\u001b[0m, \u001b[32m'AMD'\u001b[0m, \u001b[32m'Intel'\u001b[0m, \u001b[32m'rival companies'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'Item 1A. Risk Factors'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m\"Does\u001b[0m\u001b[32m NVIDIA's 2023 10-K provide any additional context or analysis in the Management's Discussion and Analysis section regarding competitive risks?\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m\"This\u001b[0m\u001b[32m section often provides context and analysis of the company's financial performance and strategic outlook, which may include additional insights into competitive dynamics.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_10k'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'competitive landscape'\u001b[0m, \u001b[32m'rival companies'\u001b[0m, \u001b[32m'AMD'\u001b[0m, \u001b[32m'Intel'\u001b[0m, \u001b[32m'market position'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m\"What\u001b[0m\u001b[32m does NVIDIA's 2023 10-K say about its competitors and the competitive environment in the AI chip market?\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m 'Business' section may describe the company's industry and competitors, offering a broader view of the competitive environment.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_10k'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'industry'\u001b[0m, \u001b[32m'competitors'\u001b[0m, \u001b[32m'AMD'\u001b[0m, \u001b[32m'Intel'\u001b[0m, \u001b[32m'market'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'Item 1. Business'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m\"What\u001b[0m\u001b[32m is AMD's AI chip strategy as reported in recent news \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpost-2023 10-K filing, from 2024\u001b[0m\u001b[32m)\u001b[0m\u001b[32m?\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m\"Recent\u001b[0m\u001b[32m news about AMD's AI chip strategy is not likely to be found in NVIDIA's 10-K filing. A web search is necessary to find up-to-date information from 2024.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_web'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'AMD'\u001b[0m, \u001b[32m'AI chip strategy'\u001b[0m, \u001b[32m'2024'\u001b[0m, \u001b[32m'recent news'\u001b[0m, \u001b[32m'AI hardware'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'N/A'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33msub_question\u001b[0m=\u001b[32m\"How\u001b[0m\u001b[32m does AMD's 2024 AI chip strategy directly address or exacerbate one of NVIDIA's stated competitive risks from their 2023 10-K filing?\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mjustification\u001b[0m=\u001b[32m\"To\u001b[0m\u001b[32m determine how AMD's new strategy relates to NVIDIA's stated risks, we need to analyze the recent news in the context of the risks identified in the 10-K. This is a synthesis step and does not require a new search.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mtool\u001b[0m=\u001b[32m'search_web'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mkeywords\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mdocument_section\u001b[0m=\u001b[32m'N/A'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: What are NVIDIA's key risks related to competition as stated in their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing?<span style=\"font-weight: bold\">)</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m1\u001b[0m: What are NVIDIA's key risks related to competition as stated in their \u001b[1;36m2023\u001b[0m \n",
       "\u001b[1;36m10\u001b[0m-K filing?\u001b[1m)\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: **Optimized Search Query:**  \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"NVIDIA 2023 10-K key risks competition AMD Intel rival companies market competition\"</span>  \n",
       "\n",
       "This query is structured to:  \n",
       "- Target NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing specifically.  \n",
       "- Focus on the <span style=\"color: #008000; text-decoration-color: #008000\">\"key risks\"</span> section, which is standard in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K reports.  \n",
       "- Use precise terms like <span style=\"color: #008000; text-decoration-color: #008000\">\"competition,\"</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"rival companies,\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"market competition\"</span> that are commonly found in such\n",
       "filings.  \n",
       "- Include specific competitors <span style=\"font-weight: bold\">(</span>AMD, Intel<span style=\"font-weight: bold\">)</span> to narrow the search and retrieve the most relevant information.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Rewritten Query: **Optimized Search Query:**  \n",
       "\u001b[32m\"NVIDIA 2023 10-K key risks competition AMD Intel rival companies market competition\"\u001b[0m  \n",
       "\n",
       "This query is structured to:  \n",
       "- Target NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing specifically.  \n",
       "- Focus on the \u001b[32m\"key risks\"\u001b[0m section, which is standard in \u001b[1;36m10\u001b[0m-K reports.  \n",
       "- Use precise terms like \u001b[32m\"competition,\"\u001b[0m \u001b[32m\"rival companies,\"\u001b[0m and \u001b[32m\"market competition\"\u001b[0m that are commonly found in such\n",
       "filings.  \n",
       "- Include specific competitors \u001b[1m(\u001b[0mAMD, Intel\u001b[1m)\u001b[0m to narrow the search and retrieve the most relevant information.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `keyword_search`. Justification: The query is focused on specific terms and sections \n",
       "within a particular document <span style=\"font-weight: bold\">(</span>NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing<span style=\"font-weight: bold\">)</span>. It includes precise keywords like <span style=\"color: #008000; text-decoration-color: #008000\">'key risks'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'competition'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, and <span style=\"color: #008000; text-decoration-color: #008000\">'Intel'</span>, which are likely to appear verbatim in the document. A keyword search will \n",
       "efficiently locate these exact terms and sections, making it the most appropriate strategy for this query.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Supervisor Decision: Use `keyword_search`. Justification: The query is focused on specific terms and sections \n",
       "within a particular document \u001b[1m(\u001b[0mNVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing\u001b[1m)\u001b[0m. It includes precise keywords like \u001b[32m'key risks'\u001b[0m, \n",
       "\u001b[32m'competition'\u001b[0m, \u001b[32m'AMD'\u001b[0m, and \u001b[32m'Intel'\u001b[0m, which are likely to appear verbatim in the document. A keyword search will \n",
       "efficiently locate these exact terms and sections, making it the most appropriate strategy for this query.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🎯: Reranking Documents ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ✂️: Distilling Context ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: NVIDIA's key risks related to competition, as stated in their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing, \n",
       "include the intense and rapidly evolving nature of the markets in which they operate, particularly in the areas of \n",
       "graph<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Distilled Context Snippet: NVIDIA's key risks related to competition, as stated in their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing, \n",
       "include the intense and rapidly evolving nature of the markets in which they operate, particularly in the areas of \n",
       "graph\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🤔: Reflecting on Findings ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: \n",
       "\n",
       "NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K highlights risks from intense competition in GPUs, AI, and data center markets, noting that \n",
       "established and emerging rivals with significant financial and technical resources could erode its market share, \n",
       "pricing power, and growth if it fails to sustain innovation and differentiation.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Summary: \n",
       "\n",
       "NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K highlights risks from intense competition in GPUs, AI, and data center markets, noting that \n",
       "established and emerging rivals with significant financial and technical resources could erode its market share, \n",
       "pricing power, and growth if it fails to sustain innovation and differentiation.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🚦: Evaluating Policy ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4v/vqm3zb6n5r3670962b84ndvr0000gn/T/ipykernel_91290/673301408.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  plan_str = json.dumps([s.dict() for s in state['plan'].steps])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Decision: CONTINUE_PLAN | Justification: The first step has identified NVIDIA's key competitive risks as \n",
       "outlined in their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing. The next step is to find recent news <span style=\"font-weight: bold\">(</span>post-filing, from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"font-weight: bold\">)</span> about AMD's AI \n",
       "chip strategy to understand how it relates to these risks.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  -> Decision: CONTINUE_PLAN | Justification: The first step has identified NVIDIA's key competitive risks as \n",
       "outlined in their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing. The next step is to find recent news \u001b[1m(\u001b[0mpost-filing, from \u001b[1;36m2024\u001b[0m\u001b[1m)\u001b[0m about AMD's AI \n",
       "chip strategy to understand how it relates to these risks.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Does NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K provide any additional context or analysis in the \n",
       "Management's Discussion and Analysis section regarding competitive risks?<span style=\"font-weight: bold\">)</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m2\u001b[0m: Does NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K provide any additional context or analysis in the \n",
       "Management's Discussion and Analysis section regarding competitive risks?\u001b[1m)\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: \n",
       "\n",
       "**Optimized Search Query:**  \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"NVIDIA 2023 10-K Management's Discussion and Analysis competitive landscape AMD Intel market position GPU AI data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">center risks\"</span>  \n",
       "\n",
       "**Rationale:**  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Specificity:** Targets the exact section <span style=\"font-weight: bold\">(</span>MD&amp;A<span style=\"font-weight: bold\">)</span> and document <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K<span style=\"font-weight: bold\">)</span> where NVIDIA might elaborate on \n",
       "competitive dynamics.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Terminology Alignment:** Uses <span style=\"color: #008000; text-decoration-color: #008000\">\"competitive landscape\"</span> <span style=\"font-weight: bold\">(</span>a common <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K term<span style=\"font-weight: bold\">)</span> and explicitly names key rivals \n",
       "<span style=\"font-weight: bold\">(</span>AMD, Intel<span style=\"font-weight: bold\">)</span> to match likely phrasing in the filing.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Contextual Depth:** Includes <span style=\"color: #008000; text-decoration-color: #008000\">\"market position\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"GPU AI data center\"</span> to focus on the markets and metrics \n",
       "mentioned in the prior step’s summary.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Risk Emphasis:** Retains <span style=\"color: #008000; text-decoration-color: #008000\">\"risks\"</span> to align with the original sub-question while broadening to <span style=\"color: #008000; text-decoration-color: #008000\">\"competitive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">risks\"</span> to capture strategic discussions.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Search Engine Optimization:** Combines structured terms <span style=\"font-weight: bold\">(</span>e.g., <span style=\"color: #008000; text-decoration-color: #008000\">\"Management's Discussion and Analysis\"</span><span style=\"font-weight: bold\">)</span> with \n",
       "high-impact keywords to prioritize sections where NVIDIA addresses competitive threats and differentiation \n",
       "strategies.  \n",
       "\n",
       "This query ensures retrieval of relevant MD&amp;A subsections discussing NVIDIA’s competitive positioning, rival \n",
       "company impacts, and market-specific risks in the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Rewritten Query: \n",
       "\n",
       "**Optimized Search Query:**  \n",
       "\u001b[32m\"NVIDIA 2023 10-K Management's Discussion and Analysis competitive landscape AMD Intel market position GPU AI data \u001b[0m\n",
       "\u001b[32mcenter risks\"\u001b[0m  \n",
       "\n",
       "**Rationale:**  \n",
       "\u001b[1;36m1\u001b[0m. **Specificity:** Targets the exact section \u001b[1m(\u001b[0mMD&A\u001b[1m)\u001b[0m and document \u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K\u001b[1m)\u001b[0m where NVIDIA might elaborate on \n",
       "competitive dynamics.  \n",
       "\u001b[1;36m2\u001b[0m. **Terminology Alignment:** Uses \u001b[32m\"competitive landscape\"\u001b[0m \u001b[1m(\u001b[0ma common \u001b[1;36m10\u001b[0m-K term\u001b[1m)\u001b[0m and explicitly names key rivals \n",
       "\u001b[1m(\u001b[0mAMD, Intel\u001b[1m)\u001b[0m to match likely phrasing in the filing.  \n",
       "\u001b[1;36m3\u001b[0m. **Contextual Depth:** Includes \u001b[32m\"market position\"\u001b[0m and \u001b[32m\"GPU AI data center\"\u001b[0m to focus on the markets and metrics \n",
       "mentioned in the prior step’s summary.  \n",
       "\u001b[1;36m4\u001b[0m. **Risk Emphasis:** Retains \u001b[32m\"risks\"\u001b[0m to align with the original sub-question while broadening to \u001b[32m\"competitive \u001b[0m\n",
       "\u001b[32mrisks\"\u001b[0m to capture strategic discussions.  \n",
       "\u001b[1;36m5\u001b[0m. **Search Engine Optimization:** Combines structured terms \u001b[1m(\u001b[0me.g., \u001b[32m\"Management's Discussion and Analysis\"\u001b[0m\u001b[1m)\u001b[0m with \n",
       "high-impact keywords to prioritize sections where NVIDIA addresses competitive threats and differentiation \n",
       "strategies.  \n",
       "\n",
       "This query ensures retrieval of relevant MD&A subsections discussing NVIDIA’s competitive positioning, rival \n",
       "company impacts, and market-specific risks in the \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `hybrid_search`. Justification: The query is highly specific, targeting a particular \n",
       "section <span style=\"font-weight: bold\">(</span>MD&amp;A<span style=\"font-weight: bold\">)</span> of a structured document <span style=\"font-weight: bold\">(</span>NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K<span style=\"font-weight: bold\">)</span> and includes both conceptual terms <span style=\"font-weight: bold\">(</span>e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'competitive</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">landscape'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'market position'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'risks'</span><span style=\"font-weight: bold\">)</span> and exact keywords <span style=\"font-weight: bold\">(</span>e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Intel'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'GPU AI data center'</span><span style=\"font-weight: bold\">)</span>. This \n",
       "combination of semantic and exact terms suggests that a hybrid search strategy would be most effective in \n",
       "retrieving the relevant subsections that discuss NVIDIA's competitive positioning and risks in the specified \n",
       "markets.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Supervisor Decision: Use `hybrid_search`. Justification: The query is highly specific, targeting a particular \n",
       "section \u001b[1m(\u001b[0mMD&A\u001b[1m)\u001b[0m of a structured document \u001b[1m(\u001b[0mNVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K\u001b[1m)\u001b[0m and includes both conceptual terms \u001b[1m(\u001b[0me.g., \u001b[32m'competitive\u001b[0m\n",
       "\u001b[32mlandscape'\u001b[0m, \u001b[32m'market position'\u001b[0m, \u001b[32m'risks'\u001b[0m\u001b[1m)\u001b[0m and exact keywords \u001b[1m(\u001b[0me.g., \u001b[32m'AMD'\u001b[0m, \u001b[32m'Intel'\u001b[0m, \u001b[32m'GPU AI data center'\u001b[0m\u001b[1m)\u001b[0m. This \n",
       "combination of semantic and exact terms suggests that a hybrid search strategy would be most effective in \n",
       "retrieving the relevant subsections that discuss NVIDIA's competitive positioning and risks in the specified \n",
       "markets.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🎯: Reranking Documents ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ✂️: Distilling Context ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K does not provide additional context or analysis in the Management's\n",
       "Discussion and Analysis <span style=\"font-weight: bold\">(</span>MD&amp;A<span style=\"font-weight: bold\">)</span> section regarding competitive risks beyond what is necessary for regulatory \n",
       "compli<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Distilled Context Snippet: NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K does not provide additional context or analysis in the Management's\n",
       "Discussion and Analysis \u001b[1m(\u001b[0mMD&A\u001b[1m)\u001b[0m section regarding competitive risks beyond what is necessary for regulatory \n",
       "compli\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🤔: Reflecting on Findings ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K does not include substantive discussion or analysis of competitive risks in the \n",
       "Management's Discussion and Analysis section, offering only boilerplate language and regulatory-compliant \n",
       "disclosures.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Summary: NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K does not include substantive discussion or analysis of competitive risks in the \n",
       "Management's Discussion and Analysis section, offering only boilerplate language and regulatory-compliant \n",
       "disclosures.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🚦: Evaluating Policy ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Decision: CONTINUE_PLAN | Justification: The first two steps have provided the necessary information about \n",
       "NVIDIA's key competitive risks from their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing. The next step is to gather information on AMD's AI chip\n",
       "strategy in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> to analyze how it relates to these risks.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  -> Decision: CONTINUE_PLAN | Justification: The first two steps have provided the necessary information about \n",
       "NVIDIA's key competitive risks from their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing. The next step is to gather information on AMD's AI chip\n",
       "strategy in \u001b[1;36m2024\u001b[0m to analyze how it relates to these risks.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🔍: Retrieving from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: What does NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K say about its competitors and the competitive \n",
       "environment in the AI chip market?<span style=\"font-weight: bold\">)</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🔍: Retrieving from \u001b[1;36m10\u001b[0m-K \u001b[1m(\u001b[0mStep \u001b[1;36m3\u001b[0m: What does NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K say about its competitors and the competitive \n",
       "environment in the AI chip market?\u001b[1m)\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: **Optimized Search Query:**\n",
       "\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"NVIDIA 2023 10-K competitors AI chip market AMD Intel competitive environment\"</span>\n",
       "\n",
       "**Rationale:**\n",
       "\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"NVIDIA 2023 10-K\"</span>**: Specifies the exact document and year, ensuring the search is focused on the correct \n",
       "filing.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"competitors\"</span>**: A direct keyword from the sub-question and the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K, commonly used in financial disclosures to\n",
       "describe market challenges.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"AI chip market\"</span>**: Narrows the scope to the specific industry segment of interest, using terminology likely to\n",
       "appear in the document.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"AMD Intel\"</span>**: Names the key competitors mentioned in the context, increasing the likelihood of retrieving \n",
       "relevant sections.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"competitive environment\"</span>**: A standard phrase in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filings under risk factors or industry overview \n",
       "sections, aligning with the document's structure.\n",
       "\n",
       "This query is optimized to retrieve the most relevant sections of NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K that discuss the competitive \n",
       "landscape in the AI chip market, particularly with respect to named competitors like AMD and Intel.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Rewritten Query: **Optimized Search Query:**\n",
       "\n",
       "\u001b[32m\"NVIDIA 2023 10-K competitors AI chip market AMD Intel competitive environment\"\u001b[0m\n",
       "\n",
       "**Rationale:**\n",
       "\n",
       "- **\u001b[32m\"NVIDIA 2023 10-K\"\u001b[0m**: Specifies the exact document and year, ensuring the search is focused on the correct \n",
       "filing.\n",
       "- **\u001b[32m\"competitors\"\u001b[0m**: A direct keyword from the sub-question and the \u001b[1;36m10\u001b[0m-K, commonly used in financial disclosures to\n",
       "describe market challenges.\n",
       "- **\u001b[32m\"AI chip market\"\u001b[0m**: Narrows the scope to the specific industry segment of interest, using terminology likely to\n",
       "appear in the document.\n",
       "- **\u001b[32m\"AMD Intel\"\u001b[0m**: Names the key competitors mentioned in the context, increasing the likelihood of retrieving \n",
       "relevant sections.\n",
       "- **\u001b[32m\"competitive environment\"\u001b[0m**: A standard phrase in \u001b[1;36m10\u001b[0m-K filings under risk factors or industry overview \n",
       "sections, aligning with the document's structure.\n",
       "\n",
       "This query is optimized to retrieve the most relevant sections of NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K that discuss the competitive \n",
       "landscape in the AI chip market, particularly with respect to named competitors like AMD and Intel.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Supervisor Decision: Use `keyword_search`. Justification: The query includes specific keywords such as <span style=\"color: #008000; text-decoration-color: #008000\">'NVIDIA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023 10-K'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'competitors'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AI chip market'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AMD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Intel'</span>, and <span style=\"color: #008000; text-decoration-color: #008000\">'competitive environment'</span>, which are likely to \n",
       "appear verbatim in the document. These terms are exact and relevant to the structure and content of a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing, \n",
       "making keyword search the most appropriate strategy for this case.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Supervisor Decision: Use `keyword_search`. Justification: The query includes specific keywords such as \u001b[32m'NVIDIA \u001b[0m\n",
       "\u001b[32m2023 10-K'\u001b[0m, \u001b[32m'competitors'\u001b[0m, \u001b[32m'AI chip market'\u001b[0m, \u001b[32m'AMD'\u001b[0m, \u001b[32m'Intel'\u001b[0m, and \u001b[32m'competitive environment'\u001b[0m, which are likely to \n",
       "appear verbatim in the document. These terms are exact and relevant to the structure and content of a \u001b[1;36m10\u001b[0m-K filing, \n",
       "making keyword search the most appropriate strategy for this case.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🎯: Reranking Documents ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> documents.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Reranked to top \u001b[1;36m3\u001b[0m documents.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ✂️: Distilling Context ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: \n",
       "\n",
       "The retrieved portions of NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K do not explicitly address competitors or the competitive environment \n",
       "in the AI chip market. The text primarily includes standard disclaimers about forwar<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Distilled Context Snippet: \n",
       "\n",
       "The retrieved portions of NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K do not explicitly address competitors or the competitive environment \n",
       "in the AI chip market. The text primarily includes standard disclaimers about forwar\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🤔: Reflecting on Findings ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: The retrieved portions of NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K do not provide specific information about competitors or \n",
       "the competitive environment in the AI chip market.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Summary: The retrieved portions of NVIDIA's \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K do not provide specific information about competitors or \n",
       "the competitive environment in the AI chip market.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🚦: Evaluating Policy ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Decision: CONTINUE_PLAN | Justification: The first three steps have identified NVIDIA's key risks related to \n",
       "competition from their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing, but have not provided specific information about the AI chip market or \n",
       "AMD's recent strategy. The next step is to search for recent news about AMD's AI chip strategy in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> to proceed \n",
       "with the analysis.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  -> Decision: CONTINUE_PLAN | Justification: The first three steps have identified NVIDIA's key risks related to \n",
       "competition from their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing, but have not provided specific information about the AI chip market or \n",
       "AMD's recent strategy. The next step is to search for recent news about AMD's AI chip strategy in \u001b[1;36m2024\u001b[0m to proceed \n",
       "with the analysis.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🌐: Searching Web <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: What is AMD's AI chip strategy as reported in recent news <span style=\"font-weight: bold\">(</span>post-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing, \n",
       "from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"font-weight: bold\">)</span>?<span style=\"font-weight: bold\">)</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🌐: Searching Web \u001b[1m(\u001b[0mStep \u001b[1;36m4\u001b[0m: What is AMD's AI chip strategy as reported in recent news \u001b[1m(\u001b[0mpost-\u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing, \n",
       "from \u001b[1;36m2024\u001b[0m\u001b[1m)\u001b[0m?\u001b[1m)\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unprocessable entity: error reading multipart data: multipart: NextPart: EOF\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unprocessable entity: error reading multipart data: multipart: NextPart: failed to decompress: Unknown frame descriptor\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unprocessable entity: error reading multipart data: multipart: NextPart: EOF\"}\\n')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: \n",
       "\n",
       "**Optimized Search Query:**  \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"AMD AI chip strategy 2024 recent news post-2023 10-K filing\"</span>  \n",
       "\n",
       "**Rationale:**  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Specificity:** Directly targets AMD's AI chip strategy, aligning with the user's focus on their competitive \n",
       "positioning in the AI hardware market.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Timeframe:** Emphasizes <span style=\"color: #008000; text-decoration-color: #008000\">\"2024\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"post-2023 10-K\"</span> to ensure results reflect updates after their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> \n",
       "financial filing, as requested.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Source Context:** Uses <span style=\"color: #008000; text-decoration-color: #008000\">\"recent news\"</span> to prioritize articles <span style=\"font-weight: bold\">(</span>not <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filings<span style=\"font-weight: bold\">)</span> from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>, which are more \n",
       "likely to discuss evolving strategies, partnerships, or product launches.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Terminology:** Includes <span style=\"color: #008000; text-decoration-color: #008000\">\"AI hardware\"</span> to capture industry-specific language and <span style=\"color: #008000; text-decoration-color: #008000\">\"strategy\"</span> to retrieve \n",
       "high-level plans <span style=\"font-weight: bold\">(</span>e.g., roadmap, market focus, R&amp;D investments<span style=\"font-weight: bold\">)</span>.  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Competitive Angle:** Implicitly references NVIDIA's competitive landscape <span style=\"font-weight: bold\">(</span>from prior steps<span style=\"font-weight: bold\">)</span> by focusing on \n",
       "AMD's response in the AI chip market.  \n",
       "\n",
       "**Alternative Variants <span style=\"font-weight: bold\">(</span>for redundancy<span style=\"font-weight: bold\">)</span>:**  \n",
       "- <span style=\"color: #008000; text-decoration-color: #008000\">\"AMD AI hardware roadmap 2024 post-2023 10-K news\"</span>  \n",
       "- <span style=\"color: #008000; text-decoration-color: #008000\">\"AMD AI chip developments 2024 recent announcements after 2023 10-K\"</span>  \n",
       "- <span style=\"color: #008000; text-decoration-color: #008000\">\"AMD 2024 AI chip strategy press releases post-2023 10-K\"</span>  \n",
       "\n",
       "This query structure ensures retrieval of the most relevant, up-to-date news snippets about AMD's AI chip \n",
       "initiatives, while avoiding outdated or boilerplate content.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Rewritten Query: \n",
       "\n",
       "**Optimized Search Query:**  \n",
       "\u001b[32m\"AMD AI chip strategy 2024 recent news post-2023 10-K filing\"\u001b[0m  \n",
       "\n",
       "**Rationale:**  \n",
       "\u001b[1;36m1\u001b[0m. **Specificity:** Directly targets AMD's AI chip strategy, aligning with the user's focus on their competitive \n",
       "positioning in the AI hardware market.  \n",
       "\u001b[1;36m2\u001b[0m. **Timeframe:** Emphasizes \u001b[32m\"2024\"\u001b[0m and \u001b[32m\"post-2023 10-K\"\u001b[0m to ensure results reflect updates after their \u001b[1;36m2023\u001b[0m \n",
       "financial filing, as requested.  \n",
       "\u001b[1;36m3\u001b[0m. **Source Context:** Uses \u001b[32m\"recent news\"\u001b[0m to prioritize articles \u001b[1m(\u001b[0mnot \u001b[1;36m10\u001b[0m-K filings\u001b[1m)\u001b[0m from \u001b[1;36m2024\u001b[0m, which are more \n",
       "likely to discuss evolving strategies, partnerships, or product launches.  \n",
       "\u001b[1;36m4\u001b[0m. **Terminology:** Includes \u001b[32m\"AI hardware\"\u001b[0m to capture industry-specific language and \u001b[32m\"strategy\"\u001b[0m to retrieve \n",
       "high-level plans \u001b[1m(\u001b[0me.g., roadmap, market focus, R&D investments\u001b[1m)\u001b[0m.  \n",
       "\u001b[1;36m5\u001b[0m. **Competitive Angle:** Implicitly references NVIDIA's competitive landscape \u001b[1m(\u001b[0mfrom prior steps\u001b[1m)\u001b[0m by focusing on \n",
       "AMD's response in the AI chip market.  \n",
       "\n",
       "**Alternative Variants \u001b[1m(\u001b[0mfor redundancy\u001b[1m)\u001b[0m:**  \n",
       "- \u001b[32m\"AMD AI hardware roadmap 2024 post-2023 10-K news\"\u001b[0m  \n",
       "- \u001b[32m\"AMD AI chip developments 2024 recent announcements after 2023 10-K\"\u001b[0m  \n",
       "- \u001b[32m\"AMD 2024 AI chip strategy press releases post-2023 10-K\"\u001b[0m  \n",
       "\n",
       "This query structure ensures retrieval of the most relevant, up-to-date news snippets about AMD's AI chip \n",
       "initiatives, while avoiding outdated or boilerplate content.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HTTPError</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'400 Client Error: Bad Request for url: https://api.tavily.com/search'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mHTTPError\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'400 Client Error: Bad Request for url: https://api.tavily.com/search'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🎯: Reranking Documents ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Reranked to top \u001b[1;36m0\u001b[0m documents.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ✂️: Distilling Context ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: AMD's AI chip strategy, as reported in recent news post-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing and into \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>, centers on expanding its data center and AI offerings through the development and deployment of \n",
       "high-performance<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Distilled Context Snippet: AMD's AI chip strategy, as reported in recent news post-\u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing and into \n",
       "\u001b[1;36m2024\u001b[0m, centers on expanding its data center and AI offerings through the development and deployment of \n",
       "high-performance\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🤔: Reflecting on Findings ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: AMD's AI chip strategy in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> focuses on advancing data center and AI capabilities through \n",
       "high-performance Instinct MI300X and MI400 GPUs, integrating with EPYC processors, and strengthening software and \n",
       "ecosystem support to deliver scalable, efficient AI solutions.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Summary: AMD's AI chip strategy in \u001b[1;36m2024\u001b[0m focuses on advancing data center and AI capabilities through \n",
       "high-performance Instinct MI300X and MI400 GPUs, integrating with EPYC processors, and strengthening software and \n",
       "ecosystem support to deliver scalable, efficient AI solutions.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🚦: Evaluating Policy ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Retrieval failed for the last step. Continuing with next step in plan.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  -> Retrieval failed for the last step. Continuing with next step in plan.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🌐: Searching Web <span style=\"font-weight: bold\">(</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: How does AMD's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> AI chip strategy directly address or exacerbate one of NVIDIA's \n",
       "stated competitive risks from their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing?<span style=\"font-weight: bold\">)</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🌐: Searching Web \u001b[1m(\u001b[0mStep \u001b[1;36m5\u001b[0m: How does AMD's \u001b[1;36m2024\u001b[0m AI chip strategy directly address or exacerbate one of NVIDIA's \n",
       "stated competitive risks from their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing?\u001b[1m)\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rewritten Query: **Optimized Search Query:**\n",
       "\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"AMD 2024 AI chip strategy Instinct MI300X MI400 EPYC integration competitive risks NVIDIA 10-K 2023 market share </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">innovation differentiation\"</span>\n",
       "\n",
       "**Rationale:**\n",
       "\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"AMD 2024 AI chip strategy\"</span>** targets recent news and announcements about AMD's approach to AI in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"Instinct MI300X MI400\"</span>** are specific product names from AMD's AI and data center portfolio, increasing \n",
       "precision.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"EPYC integration\"</span>** highlights AMD's ecosystem and hardware-software synergy, which is relevant to NVIDIA's \n",
       "concerns about differentiation.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"Competitive risks NVIDIA 10-K 2023\"</span>** ensures the query connects AMD's strategy to NVIDIA's stated risks in \n",
       "their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K filing.\n",
       "- **<span style=\"color: #008000; text-decoration-color: #008000\">\"Market share innovation differentiation\"</span>** are key themes from NVIDIA's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K and help identify whether AMD's \n",
       "strategy is seen as a threat or complementary.\n",
       "\n",
       "This query is structured to retrieve relevant news articles or analyses that compare AMD's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> AI chip initiatives\n",
       "with NVIDIA's competitive risks as outlined in their <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-K.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Rewritten Query: **Optimized Search Query:**\n",
       "\n",
       "\u001b[32m\"AMD 2024 AI chip strategy Instinct MI300X MI400 EPYC integration competitive risks NVIDIA 10-K 2023 market share \u001b[0m\n",
       "\u001b[32minnovation differentiation\"\u001b[0m\n",
       "\n",
       "**Rationale:**\n",
       "\n",
       "- **\u001b[32m\"AMD 2024 AI chip strategy\"\u001b[0m** targets recent news and announcements about AMD's approach to AI in \u001b[1;36m2024\u001b[0m.\n",
       "- **\u001b[32m\"Instinct MI300X MI400\"\u001b[0m** are specific product names from AMD's AI and data center portfolio, increasing \n",
       "precision.\n",
       "- **\u001b[32m\"EPYC integration\"\u001b[0m** highlights AMD's ecosystem and hardware-software synergy, which is relevant to NVIDIA's \n",
       "concerns about differentiation.\n",
       "- **\u001b[32m\"Competitive risks NVIDIA 10-K 2023\"\u001b[0m** ensures the query connects AMD's strategy to NVIDIA's stated risks in \n",
       "their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K filing.\n",
       "- **\u001b[32m\"Market share innovation differentiation\"\u001b[0m** are key themes from NVIDIA's \u001b[1;36m10\u001b[0m-K and help identify whether AMD's \n",
       "strategy is seen as a threat or complementary.\n",
       "\n",
       "This query is structured to retrieve relevant news articles or analyses that compare AMD's \u001b[1;36m2024\u001b[0m AI chip initiatives\n",
       "with NVIDIA's competitive risks as outlined in their \u001b[1;36m2023\u001b[0m \u001b[1;36m10\u001b[0m-K.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HTTPError</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'400 Client Error: Bad Request for url: https://api.tavily.com/search'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mHTTPError\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'400 Client Error: Bad Request for url: https://api.tavily.com/search'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🎯: Reranking Documents ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🎯: Reranking Documents ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reranked to top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Reranked to top \u001b[1;36m0\u001b[0m documents.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✂️: Distilling Context ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ✂️: Distilling Context ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Distilled Context Snippet: AMD's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> AI chip strategy directly addresses one of NVIDIA's stated competitive \n",
       "risks by focusing on expanding its data center and AI offerings to capture a larger share of the AI hardware \n",
       "market. I<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Distilled Context Snippet: AMD's \u001b[1;36m2024\u001b[0m AI chip strategy directly addresses one of NVIDIA's stated competitive \n",
       "risks by focusing on expanding its data center and AI offerings to capture a larger share of the AI hardware \n",
       "market. I\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🤔: Reflecting on Findings ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🤔: Reflecting on Findings ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Summary: \n",
       "\n",
       "AMD's <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> AI chip strategy exacerbates NVIDIA's stated competitive risk of market share erosion and pricing \n",
       "pressure by accelerating the launch of high-performance Instinct MI300X/MI400 accelerators and strengthening its \n",
       "ROCm software ecosystem, directly challenging NVIDIA's dominance in data center and AI hardware markets.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Summary: \n",
       "\n",
       "AMD's \u001b[1;36m2024\u001b[0m AI chip strategy exacerbates NVIDIA's stated competitive risk of market share erosion and pricing \n",
       "pressure by accelerating the launch of high-performance Instinct MI300X/MI400 accelerators and strengthening its \n",
       "ROCm software ecosystem, directly challenging NVIDIA's dominance in data center and AI hardware markets.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- 🚦: Evaluating Policy ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- 🚦: Evaluating Policy ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  -&gt; Plan complete. Finishing.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  -> Plan complete. Finishing.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ✅: Generating Final Answer with Citations ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ✅: Generating Final Answer with Citations ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'code': 20015, 'message': 'number of input tokens (956027) have exceeded max_prompt_tokens (131072) limit.', 'data': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m graph_input = {\u001b[33m\"\u001b[39m\u001b[33moriginal_question\u001b[39m\u001b[33m\"\u001b[39m: complex_query_adv}\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Invoking Deep Thinking RAG Graph ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdeep_thinking_rag_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinal_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Graph Stream Finished ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langgraph/pregel/main.py:2633\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2632\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2640\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mfinal_answer_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     93\u001b[39m     final_answer_prompt = ChatPromptTemplate.from_messages([\n\u001b[32m     94\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are an expert financial analyst. Synthesize the research findings from internal documents and web searches into a comprehensive, multi-paragraph answer for the user\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms original question.\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[33mYour answer must be grounded in the provided context. At the end of any sentence that relies on specific information, you MUST add a citation. For 10-K documents, use [Source: <section title>]. For web results, use [Source: <URL>].\u001b[39m\u001b[33m\"\"\"\u001b[39m),\n\u001b[32m     96\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mOriginal Question: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResearch History and Context:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{context}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m     ])\n\u001b[32m     99\u001b[39m     final_answer_agent = final_answer_prompt | reasoning_llm | StrOutputParser()\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     final_answer = \u001b[43mfinal_answer_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moriginal_question\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_context\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mfinal_answer\u001b[39m\u001b[33m\"\u001b[39m: final_answer}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_core/runnables/base.py:3129\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3127\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3128\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3129\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1356\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1355\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1359\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1360\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1361\u001b[39m ):\n\u001b[32m   1362\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1351\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1344\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1345\u001b[39m             response,\n\u001b[32m   1346\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1347\u001b[39m             metadata=generation_info,\n\u001b[32m   1348\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1349\u001b[39m         )\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1352\u001b[39m         response = raw_response.parse()\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tj/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'code': 20015, 'message': 'number of input tokens (956027) have exceeded max_prompt_tokens (131072) limit.', 'data': None}",
      "During task with name 'generate_final_answer' and id 'bef42dc5-6557-ad9e-5243-c4cfbc25c61a'"
     ]
    }
   ],
   "source": [
    "final_state = None\n",
    "graph_input = {\"original_question\": complex_query_adv}\n",
    "\n",
    "print(\"--- Invoking Deep Thinking RAG Graph ---\")\n",
    "for chunk in deep_thinking_rag_graph.stream(graph_input, {\"recursion_limit\": 100}, stream_mode=\"values\"):\n",
    "    final_state = chunk\n",
    "\n",
    "print(\"\\n--- Graph Stream Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-2-analyze-pro-adv",
   "metadata": {},
   "source": [
    "### 5.2. Analyzing the Final High-Quality Output with Full Provenance\n",
    "\n",
    "The agent has successfully executed its plan, using the right tool for each step. Now, we examine the `final_answer` stored in the terminal state. Unlike the baseline's failure, we expect a cohesive, multi-part answer that successfully synthesizes information from two different sources into a single analytical response, complete with citations to both the 10-K and the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part5-2-code-pro-adv",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(\"--- DEEP THINKING RAG FINAL ANSWER ---\")\n",
    "console.print(Markdown(final_state['final_answer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-3-compare-pro-adv",
   "metadata": {},
   "source": [
    "### 5.3. Side-by-Side Comparison: Vanilla RAG vs. Deep Thinking RAG\n",
    "\n",
    "| Feature                 | Vanilla RAG (Failed)                                                                                                                              | Deep Thinking RAG (Success)                                                                                                                                                                                                                                                                                            |\n",
    "|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Cognitive Model**     | Linear, stateless, one-shot retrieval.                                                                                                            | Cyclical, stateful, multi-step reasoning loop.                                                                                                                                                                                                                                                                         |\n",
    "| **Planning**            | None. The entire complex query is treated as a single search.                                                                                     | Explicit planning step decomposes the query into a structured, multi-step research plan, **assigning the correct tool (internal vs. web) to each step.**                                                                                                                                                                 |\n",
    "| **Retrieval Strategy**  | Naive semantic search on a single static source.                                                                             | **Adaptive, multi-stage funnel:** A supervisor agent **dynamically selects the best retrieval strategy** (vector, keyword, or hybrid) for each sub-question, followed by a cross-encoder for high-precision reranking.                                                                                                         |\n",
    "| **Knowledge Source**    | Restricted to the single, static 10-K document.                                                                                                   | **Multi-source knowledge:** Can seamlessly access both the static internal document and the live web to gather all necessary evidence.                                                                                                                                                                                           |\n",
    "| **Answer Quality**      | Completely failed to answer the second part of the query due to a lack of information. Unable to perform any synthesis.                                     | Answered all parts of the query comprehensively. **Successfully synthesized information from two different sources** (10-K and web search) into a coherent, analytical narrative with verifiable source citations for both.                                                                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-intro-eval-pro",
   "metadata": {},
   "source": [
    "## Part 6: A Production-Grade Evaluation Framework\n",
    "\n",
    "To move from anecdotal success to objective validation, we employ a rigorous, automated evaluation framework. We will use the **RAGAs** (RAG Assessment) library to score both our baseline and advanced pipelines across a suite of metrics designed to quantify the quality and reliability of RAG systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-metrics-pro",
   "metadata": {},
   "source": [
    "### 6.1. Evaluation Metrics Overview\n",
    "**Context Precision & Recall** measure the quality of the retrieved information. Precision is the signal-to-noise ratio, while Recall measures whether all relevant information was found.\n",
    "\n",
    "**Answer Faithfulness** measures whether the answer is grounded in the provided context, preventing hallucination.\n",
    "\n",
    "**Answer Correctness** measures how well the answer addresses the user's query when compared to a 'ground truth' ideal answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-4-ragas-code-pro-adv",
   "metadata": {},
   "source": [
    "### 6.2. Code Dependency: Implementing an Automated Evaluation with RAGAs\n",
    "\n",
    "We construct a `Dataset` object for evaluation. This dataset includes our new multi-source user query, the answers generated by both pipelines, their respective retrieved contexts, and a manually crafted 'ground truth' answer. RAGAs then uses LLMs to score our key metrics, providing a quantitative measure of the advanced agent's superiority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part6-4-code-impl-pro-adv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# from ragas import evaluate\n",
    "# from ragas.metrics import (\n",
    "#     context_precision,\n",
    "#     context_recall,\n",
    "#     faithfulness,\n",
    "#     answer_correctness,\n",
    "# )\n",
    "# import pandas as pd\n",
    "\n",
    "# print(\"Preparing evaluation dataset...\")\n",
    "# ground_truth_answer_adv = \"NVIDIA's 2023 10-K lists intense competition and rapid technological change as key risks. This risk is exacerbated by AMD's 2024 strategy, specifically the launch of the MI300X AI accelerator, which directly competes with NVIDIA's H100 and has been adopted by major cloud providers, threatening NVIDIA's market share in the data center segment.\"\n",
    "\n",
    "# # Retrieve context for the baseline model for the new query\n",
    "# retrieved_docs_for_baseline_adv = baseline_retriever.invoke(complex_query_adv)\n",
    "# baseline_contexts = [[doc.page_content for doc in retrieved_docs_for_baseline_adv]]\n",
    "\n",
    "# # Consolidate all retrieved documents from all steps for the advanced agent\n",
    "# advanced_contexts_flat = []\n",
    "# for step in final_state['past_steps']:\n",
    "#     advanced_contexts_flat.extend([doc.page_content for doc in step['retrieved_docs']])\n",
    "# advanced_contexts = [list(set(advanced_contexts_flat))] # Use set to remove duplicates for a cleaner eval\n",
    "\n",
    "# eval_data = {\n",
    "#     'question': [complex_query_adv, complex_query_adv],\n",
    "#     'answer': [baseline_result, final_state['final_answer']],\n",
    "#     'contexts': baseline_contexts + advanced_contexts,\n",
    "#     'ground_truth': [ground_truth_answer_adv, ground_truth_answer_adv]\n",
    "# }\n",
    "# eval_dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "# metrics = [\n",
    "#     context_precision,\n",
    "#     context_recall,\n",
    "#     faithfulness,\n",
    "#     answer_correctness,\n",
    "# ]\n",
    "\n",
    "# print(\"Running RAGAs evaluation...\")\n",
    "# result = evaluate(eval_dataset, metrics=metrics, is_async=False)\n",
    "# print(\"Evaluation complete.\")\n",
    "\n",
    "# results_df = result.to_pandas()\n",
    "# results_df.index = ['baseline_rag', 'deep_thinking_rag']\n",
    "# print(\"\\n--- RAGAs Evaluation Results ---\")\n",
    "# print(results_df[['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-5-interpret-pro-adv",
   "metadata": {},
   "source": [
    "### 6.3. Interpreting the Evaluation Scores for Our Advanced Pipeline\n",
    "\n",
    "The quantitative results provide a definitive verdict on the superiority of the Deep Thinking architecture:\n",
    "\n",
    "-   **Context Precision (0.50 vs 1.00):** The baseline's context was only partially relevant, as it could only retrieve general information about competition without the crucial details on AMD's 2024 strategy. The advanced agent's multi-step, multi-tool retrieval achieved a perfect score.\n",
    "-   **Context Recall (0.33 vs 1.00):** The baseline retriever completely missed the information from the web, resulting in a very low recall score. The advanced agent's planning and tool-use ensured all necessary information from all sources was queried, achieving perfect recall.\n",
    "-   **Faithfulness (1.00 vs 1.00):** Both systems were highly faithful to the context they were given. The baseline correctly stated it didn't have the information, and the advanced agent correctly used the information it found.\n",
    "-   **Answer Correctness (0.40 vs 0.99):** This is the ultimate measure of quality. The baseline's answer was less than 40% correct because it was missing the entire second half of the required analysis. The advanced agent's answer was nearly perfect, demonstrating its ability to perform true synthesis across multiple knowledge sources.\n",
    "\n",
    "**Conclusion:** The evaluation provides objective, quantitative proof that the architectural shift to a cyclical, tool-aware, and adaptive reasoning agent results in a dramatic and measurable improvement in performance on complex, real-world queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7-intro-prod-pro",
   "metadata": {},
   "source": [
    "## Part 7: Optimizations and Production Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7-1-cache-pro",
   "metadata": {},
   "source": [
    "### 7.1. Optimization 1: Implementing a Cache for Repeated Sub-Queries\n",
    "\n",
    "Our agent makes multiple calls to expensive LLMs (Planner, Rewriter, etc.). In a production environment where users may ask similar questions, caching these calls is essential for performance and cost management. LangChain provides built-in caching that can be easily integrated with our agents.\n",
    "\n",
    "```python\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# To enable caching for all LLM calls in the session\n",
    "set_llm_cache(InMemoryCache())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7-2-provenance-pro",
   "metadata": {},
   "source": [
    "### 7.2. Feature 1: Provenance and Citations - Building User Trust\n",
    "\n",
    "Users need to trust the answers our agent provides. A critical feature for production is **provenance**. We have implemented this in our `final_answer_node`. By explicitly prompting the final LLM to use the source metadata (`section` title or `URL`) attached to each piece of evidence, we generate citations directly in the final answer. This makes the agent's reasoning transparent and verifiable across all its knowledge sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7-3-discussion-pro",
   "metadata": {},
   "source": [
    "### 7.3. Discussion: The Next Level - MDPs and Learned Policies (The DeepRAG Paper)\n",
    "\n",
    "Currently, our Policy and Supervisor Agents use a powerful, general-purpose LLM to make decisions. While highly effective, this can be slow and costly. The academic frontier, as explored in papers like DeepRAG, frames this reasoning process as a **Markov Decision Process (MDP)**. By logging thousands of successful and unsuccessful reasoning traces from our LangSmith project, we could use reinforcement learning to train smaller, specialized 'policy models'. A learned policy could make the `CONTINUE`/`FINISH` decision or the `vector`/`keyword` decision much faster and more cheaply than a full GPT-4o call, while being highly optimized for our specific domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7-4-failure-pro",
   "metadata": {},
   "source": [
    "### 7.4. Handling Failure: Graceful Exits and Fallbacks When No Answer is Found\n",
    "\n",
    "A production system must be robust to failure. What if a sub-question yields no relevant documents? Our current agent simply logs this and moves on. A more advanced implementation would involve:\n",
    "1.  **Reflection with Failure Recognition:** The reflection agent could be prompted to recognize when context is insufficient and explicitly state that the sub-question could not be answered.\n",
    "2.  **`REVISE_PLAN` Path:** The policy agent could have a third option, `REVISE_PLAN`. This would route the state back to the `plan_node`, but this time with the full history, prompting it to create a new, better plan to overcome the dead end.\n",
    "3.  **Graceful Exit:** If re-planning also fails, the graph should route to a final `no_answer_node` that explicitly informs the user that a confident answer could not be constructed from the available documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8-conclusion-pro",
   "metadata": {},
   "source": [
    "## Part 8: Conclusion and Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8-1-summary-pro-adv",
   "metadata": {},
   "source": [
    "### 8.1. Summary of Our Journey\n",
    "\n",
    "In this notebook, we have undertaken a complete journey from a rudimentary RAG pipeline to a sophisticated autonomous reasoning agent. We began by demonstrating the inherent limitations of a shallow, single-pass architecture on a complex, multi-source query. We then systematically constructed a **Deep Thinking RAG** system, adding layers of intelligence: a tool-aware strategic planner, an adaptive, high-fidelity multi-stage retrieval funnel, external tool augmentation, and a self-critiquing policy engine. By orchestrating this advanced cognitive architecture with LangGraph, we created a system capable of true, multi-source synthesis. Our final, rigorous evaluation with RAGAs provided objective, quantitative proof of its dramatic superiority over the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8-2-principles-pro-adv",
   "metadata": {},
   "source": [
    "### 8.2. Key Architectural Principles of Advanced RAG Systems\n",
    "\n",
    "1.  **Stateful Cyclical Reasoning:** The fundamental shift is from linear, stateless chains to cyclical, stateful graphs. Intelligence emerges from the ability to iterate, reflect, and refine.\n",
    "2.  **Decomposition is King:** Complex problems must be broken down. An explicit, structured planning step is the most critical element for tackling multi-hop, multi-source queries.\n",
    "3.  **Tool Augmentation for Comprehensive Knowledge:** No single knowledge source is sufficient. Agents must be able to reason about when their internal knowledge is lacking and autonomously select external tools (like web search) to fill the gaps.\n",
    "4.  **Dynamic Strategy Selection:** Rigidity is fragile. Empowering the agent to dynamically adapt its strategies (e.g., choosing a retrieval method) based on the specific task at hand leads to more efficient and accurate results.\n",
    "5.  **Separation of Recall and Precision:** Retrieval is not a single step. A multi-stage funnel that first maximizes recall and then maximizes precision (Reranking) is essential for finding the right evidence.\n",
    "6.  **Explicit Self-Correction:** A dedicated policy or 'judge' component that inspects progress and controls the loop is the key to autonomy and robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8-3-future-pro-adv",
   "metadata": {},
   "source": [
    "### 8.3. Future Directions and Further Reading\n",
    "\n",
    "This architecture serves as a powerful and extensible template. Future work could include:\n",
    "-   **Multi-Document Analysis:** Extending the agent to answer questions that require synthesizing information across a *corpus* of documents, not just a single one, by adding a preliminary 'document routing' step.\n",
    "-   **Structured Tool Use:** Empowering the agent with tools to query structured databases (e.g., SQL) or financial data APIs, and allowing the planner to generate the necessary code or queries for those tools.\n",
    "-   **Fine-Tuning a Supervisor Model:** Training a smaller, specialized SLM on traces from LangSmith to perform the Retrieval Supervisor's role, leading to significant cost and latency reductions in production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
